{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Contar Valores ausentes**\n",
    "\n",
    "En las próximas lecciones, trabajaremos con un conjunto de datos de marketing de una empresa de comercio electrónico. Los datos están en un archivo CSV llamado visit_log.csv y cada fila representa una visita al sitio web de una empresa. Hay cuatro columnas:\n",
    "\n",
    "- 'user_id': identificador único para cada persona que visita el sitio web.\n",
    "- 'source': fuente de tráfico de la visita al sitio web. Aquí nos interesan tres categorías para la fuente:\n",
    "Visitas desde enlaces de marketing por correo electrónico: 'email'\n",
    "\n",
    "Visitas de anuncios contextuales en línea: 'context'\n",
    "\n",
    "Visitas de cualquier otra fuente: 'other'\n",
    "- 'email': dirección de correo electrónico encriptada asociada con la persona que visita el sitio.\n",
    "- 'purchase': indica si la persona compró algo en esa visita (1 en caso afirmativo, 0 en caso negativo).\n",
    "\n",
    "Tu objetivo es determinar la tasa de conversión para cada fuente, que es la proporción de visitas en las que se realizó una compra con respecto al número total de visitas en general. Comparar la tasa de conversión para cada fuente te permitirá determinar cuál de ellas genera la mayor cantidad de ventas.\n",
    "\n",
    "Pero antes de profundizar en los cálculos, necesitamos revisar el conjunto de datos para buscar valores ausentes y decidir qué hacer con ellos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BUSCAR VALORES AUSENTES**\n",
    "\n",
    "- **USAR EL MÉTODO INFO YA QUE TE DA LA INFORMACIÓN DE LOS NO SON AUSENTES, POR LO TANTO, TENDRÁS POR DESCARTE LOS AUSENTES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "print(df_logs.info())\n",
    "\n",
    "# RESULTADO =============================\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 200000 entries, 0 to 199999\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count   Dtype \n",
    "---  ------    --------------   ----- \n",
    " 0   user_id   200000 non-null  int64 \n",
    " 1   source    198326 non-null  object\n",
    " 2   email     13953 non-null   object\n",
    " 3   purchase  200000 non-null  int64 \n",
    "dtypes: int64(2), object(2)\n",
    "memory usage: 6.1+ MB\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PERO TAMBIEN PUEDES UTILIZAR ISNULL().SUM()**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs.isnull().sum())\n",
    "\n",
    "#RESULTADO====================================================\n",
    "\n",
    "user_id          0\n",
    "source        1674\n",
    "email       186047\n",
    "purchase         0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contar los valores ausentes con value_counts()**\n",
    "\n",
    "En vez de sumar los valores obtenidos con isna(), podemos contar los valores ausentes con el método value_counts(). Al llamarlo en una sola columna (es decir, un Series), devuelve la cantidad de veces que cada valor único aparece en esa columna.\n",
    "\n",
    "Este método tiene un parámetro llamado dropna=, que se establece por defecto en True. Esto significa que value_counts() excluirá los valores None o NaN a menos que establezcas dropna=False.\n",
    "\n",
    "Utilicémoslo en la columna 'source' de nuestro DataFrame, asegurándonos de incluir los valores ausentes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs['source'].value_counts(dropna = False))\n",
    "\n",
    "#Resultado===================================================\n",
    "other      133834\n",
    "context     52032\n",
    "email       12279\n",
    "NaN          1674\n",
    "undef         181\n",
    "Name: source, dtype: int64\n",
    "\n",
    "#Ahora tenemos un recuento de todos esos valores de NaN.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, cuando imprimimos df_logs['source'].value_counts(dropna=False), la salida se ordena en orden descendente según el recuento de cada valor. Alternativamente, podemos ordenar la salida alfabéticamente según los nombres de los valores. Para hacerlo, podemos utilizar el método sort_index().\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs['source'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "#RESULTADO =================================\n",
    "source\n",
    "context     52032\n",
    "email       12279\n",
    "other      133834\n",
    "undef         181\n",
    "NaN          1674\n",
    "Name: count, dtype: int64\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Resumen**\n",
    "\n",
    "Hay muchas formas de encontrar y contar valores ausentes en pandas. En esta lección aprendiste tres maneras:\n",
    "- Llamar a info() en un DataFrame.\n",
    "- Llamar a isna().sum() en un DataFrame o un Series.\n",
    "- Llamar a value_counts(dropna=False) en un Series.\n",
    "\n",
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Ahora aplica el método value_counts() a la columna 'email' y almacena el resultado en la variable email_values. Esta vez, no incluyas los valores ausentes en la salida. Imprime el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "email_values = df_logs['email'].value_counts()\n",
    "\n",
    "print(email_values)\n",
    "\n",
    "#Resultado============================\n",
    "\n",
    "4526cc437a    9\n",
    "410a2a3c23    9\n",
    "17c4fb26f9    8\n",
    "5a4c033120    7\n",
    "33f8a3d521    7\n",
    "             ..\n",
    "05d06bf263    1\n",
    "5e66f8634e    1\n",
    "35264deaa4    1\n",
    "fad76d6955    1\n",
    "7516495ced    1\n",
    "Name: email, Length: 6062, dtype: int64\n",
    "\n",
    "#Ahora vemos cómo quedan los valores de la columna 'email'. ¡Hay muchos! Parece que no es el mejor enfoque para examinar los valores ausentes en esta columna. Y sin embargo, ¡no está de más saberlo!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Ahora intentemos ordenar los resultados por índice en lugar de valores para ver si se añade algún significado a los valores de la columna 'email'. Vuelve a escribir la variable email_values utilizando la ordenación e imprime el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "email_values = df_logs['email'].value_counts()\n",
    "email_values = email_values.sort_index()\n",
    "\n",
    "print(email_values)\n",
    "\n",
    "#Resultado====================================\n",
    "000b6d0fb5    3\n",
    "000eb3c3df    4\n",
    "0017c0065d    4\n",
    "001c287e32    6\n",
    "002020511f    1\n",
    "             ..\n",
    "ff953ec581    1\n",
    "ffa51139e7    2\n",
    "ffcef1ce43    2\n",
    "ffe64c4d89    5\n",
    "fffc7f0482    1\n",
    "Name: email, Length: 6062, dtype: int64\n",
    "\n",
    "#Hasta ahora nada de información valiosa. Somos detectives de los datos. Es mejor intentarlo y fallar que no intentarlo del todo.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FILTRAR DATAFRAMES CON NaNs**\n",
    "\n",
    "```python\n",
    "print(df_logs[df_logs['source'].isna()]) \n",
    "\n",
    "#Resultado\n",
    "                     user_id source       email  purchase\n",
    "22      1397217221    NaN  79ac569f0b         0\n",
    "49      5062457902    NaN  9ddce3a861         0\n",
    "171     6724868284    NaN  c0e48c7cf8         0\n",
    "258     3221384063    NaN  7fe8da1823         0\n",
    "379     7515782311    NaN  462462af10         0\n",
    "...            ...    ...         ...       ...\n",
    "199342  3439213943    NaN  7edda4e2a4         0\n",
    "199661  9473123762    NaN  3535509f51         0\n",
    "199689   722485056    NaN  470ffa3800         0\n",
    "199709  5950023506    NaN  0fb749d485         0\n",
    "199758  3747926428    NaN  604850216f         0\n",
    "\n",
    "[1674 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a desglosar esta línea de código:\n",
    "\n",
    "- Extraemos la columna 'source' utilizando df_logs['source']\n",
    "- A continuación, le aplicamos el método isna() para obtener una serie de booleanos que indican la ausencia de valores: df_logs['source'].isna()\n",
    "- Utilizamos esta serie de booleanos para filtrar el DataFrame original, extrayendo solamente las filas en las que 'source' no tiene valores ausentes.\n",
    "- Por último, imprimimos la tabla resultante.\n",
    "\n",
    "Otra opción es filtrar el DataFrame y extraer sólo las filas en las que no falte 'source'. El enfoque que utilizamos anteriormente funcionará con una única modificación menor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Múltiples condiciones de filtrado**\n",
    "\n",
    "Podemos filtrar un DataFrame a partir de múltiples condiciones. Por ejemplo, para crear un DataFrame que no tenga valores ausentes en la columna 'email' y solo el valor 'email' en la columna 'source', podemos emplear el siguiente código:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')])\n",
    "\n",
    " #Resultado ============================================\n",
    "                      user_id source       email  purchase\n",
    "1       5644686960  email  c129aa540a         0\n",
    "11      8623045648  email  d6d19c571c         0\n",
    "18      5739438900  email  19379ee49c         0\n",
    "19      7486955288  email  09c27794fa         0\n",
    "33      7298923004  email  1fe184ed73         0\n",
    "...            ...    ...         ...       ...\n",
    "199922  4075894991  email  2c9a202435         0\n",
    "199958  9794381984  email  85712b433a         0\n",
    "199970  3396355438  email  4bba3fde78         0\n",
    "199979  5008169696  email  e5128e15fd         0\n",
    "199989  9470921783  email  3977de6aaa         0\n",
    "\n",
    "[12279 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de filtrado anterior consta de dos partes:\n",
    "\n",
    "- (~df_logs['email'].isna()) devuelve una serie de booleanos donde True indica que no falta ningún valor en la columna 'email'.\n",
    "- (df_logs['source'] == 'email') devuelve una serie de booleanos, donde True indica que 'source' tiene 'email' como valor, y False indica lo contrario.\n",
    "- Comprobamos dos series de booleanos para ver dónde ambas condiciones devuelven True. Utilizamos el símbolo & para representar el operador lógico and. Las filas que cumplen ambas condiciones (es decir, que cumplen la primera condición y la segunda) se incluyen en el resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EJERCICIOS**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Anteriormente determinamos que la columna 'email' tiene 13 953 valores no ausentes. ¡Eso significa que más del 90% de los datos están ausentes! Filtra el DataFrame df_logs para que solo contenga filas donde no haya valores ausentes en la columna 'email'. Asigna el resultado filtrado a una variable llamada df_emails, luego imprime las primeras 10 filas.\n",
    "\n",
    "Para comprobar si una condición no es verdadera al filtrar un DataFrame, precede la condición con el carácter ~ (por ejemplo, df[~df.method()])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "df_emails = df_logs[~df_logs['email'].isna()]\n",
    "print(df_emails.head(10))\n",
    "\n",
    "#RESULTADO ======================================\n",
    "\n",
    "       user_id source       email  purchase\n",
    "1   5644686960  email  c129aa540a         0\n",
    "11  8623045648  email  d6d19c571c         0\n",
    "18  5739438900  email  19379ee49c         0\n",
    "19  7486955288  email  09c27794fa         0\n",
    "22  1397217221    NaN  79ac569f0b         0\n",
    "33  7298923004  email  1fe184ed73         0\n",
    "43  6034222291  email  fb58a27f03         0\n",
    "49  5062457902    NaN  9ddce3a861         0\n",
    "56  5690036640  email  a088a48182         0\n",
    "66  9963049355  email  9cc43ebd15         0 \n",
    "\n",
    "#Ahora solo tienes filas donde hay una dirección de correo electrónico asociada con la visita. ¡Combinar ~ con isna() es una excelente manera de filtrar las filas con valores ausentes!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "La columna 'source' muestra que muchas de estas visitas procedían de enlaces de correo electrónico de marketing. Pero también hay algunos valores NaN. Es posible que las visitas con una dirección de correo electrónico, pero sin un valor 'source', también provengan de enlaces de marketing por correo electrónico, pero que la fuente no se haya registrado.\n",
    "\n",
    "Comprueba si hay filas con valores ausentes en las columnas 'source' y 'email'. Si no hay ninguna fila en la que ambas condiciones sean verdaderas, entonces es una buena señal de que los valores ausentes en la columna 'source' deberían ser 'email'.\n",
    "\n",
    "Filtra df_logs en la condición donde las columnas 'email' y 'source' tienen valores ausentes. Asigna el resultado a una variable llamada df_emails y luego imprímelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "df_emails = df_logs[df_logs['email'].isna() & df_logs['source'].isna()]\n",
    "print(df_emails)\n",
    "\n",
    "#Resultado =======================================\n",
    "\n",
    "Empty DataFrame\n",
    "Columns: [user_id, source, email, purchase]\n",
    "Index: []\n",
    "\n",
    "#¡El DataFrame filtrado está vacío! Eso significa que no hay filas en las que 'source' y 'email' tengan valores ausentes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rellenar los valores categóricos ausentes**\n",
    "\n",
    "Los valores NaN en la columna 'email' sustituyen a las direcciones de correo electrónico de los usuarios y las usuarias que no se suscribieron al boletín de la tienda. Ya que no hay forma de averiguar sus direcciones de correo electrónico, no podemos rellenar manualmente los valores ausentes con datos significativos.\n",
    "\n",
    "Pero podemos rellenarlos con un valor por defecto para representar los correos electrónicos ausentes. Sustituyamos los valores ausentes en la columna 'email' por la cadena vacía '' como valor por defecto.\n",
    "\n",
    "- Utiliza el método fillna() para sustituir los valores ausentes en 'email' por cadenas vacías.\n",
    "- Imprime las cinco primeras filas del DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "# Rellenar NaN en la columna 'email' con espacio en blanco\n",
    "df_logs['email'].fillna(value='', inplace=True)\n",
    "\n",
    "# Imprimir la cabecera del DataFrame después de reemplazar\n",
    "print(df_logs.head())\n",
    "\n",
    "#Resultado ========================\n",
    "\n",
    "      user_id   source       email  purchase\n",
    "0  7141786820    other                     0\n",
    "1  5644686960    email  c129aa540a         0\n",
    "2  1914055396  context                     0\n",
    "3  4099355752    other                     0\n",
    "4  6032477554  context                     1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **El parámetro keep_default_na=**\n",
    "\n",
    "Si observas los datos de texto sin procesar en el archivo visit_log.csv, encontrarás que los valores ausentes están representados por la ausencia de texto. En otras palabras, la ausencia de texto en visit_log.csv se interpreta como NaN. Consulta el archivo CSV en la pestaña de la lección.\n",
    "\n",
    "Pero podemos hacer que read_csv() lea la ausencia de texto como cadenas vacías en lugar de NaN, configurando el parámetro keep_default_na= en False. Probémoslo en nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "print(df_logs.head())\n",
    "print()\n",
    "df_logs.info()\n",
    "\n",
    "#Resultado ==========================\n",
    "\n",
    "      user_id   source       email  purchase\n",
    "0  7141786820    other                     0\n",
    "1  5644686960    email  c129aa540a         0\n",
    "2  1914055396  context                     0\n",
    "3  4099355752    other                     0\n",
    "4  6032477554  context                     1\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 200000 entries, 0 to 199999\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count   Dtype \n",
    "---  ------    --------------   ----- \n",
    " 0   user_id   200000 non-null  int64 \n",
    " 1   source    200000 non-null  object\n",
    " 2   email     200000 non-null  object\n",
    " 3   purchase  200000 non-null  int64 \n",
    "dtypes: int64(2), object(2)\n",
    "memory usage: 6.1+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Genial! ¡Ahora vamos a arreglar nuestros valores ausentes!\n",
    "- Utiliza replace() para reemplazar los valores ausentes en la columna 'source' por la cadena 'email'.\n",
    "- Verifica tu trabajo llamando al método unique() en la columna 'source' e imprime los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#ANTES EL CÓDIGO ERA ASI\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "#df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "#df_sources = df_logs['source'].unique()\n",
    "#print(df_sources)\n",
    "\n",
    "#Resultado========================\n",
    "#['other' 'email' 'context' '' 'undef']\n",
    "\n",
    "```\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "df_logs['source'] = df_logs['source'].replace('','email')\n",
    "\n",
    "print(df_logs['source'].unique())\n",
    "\n",
    "Resultado==============\n",
    "['other' 'email' 'context' 'undef']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Para calcular la tasa de conversión de cada fuente de tráfico, primero determina cuántas visitas hubo de cada fuente.\n",
    "\n",
    "Para encontrar el número total de visitas de cada fuente de tráfico, utiliza groupby() para agrupar los datos por la columna 'source', luego cuenta el número de valores en la columna 'user_id' del DataFrame agrupado. Asigna el resultado en la variable visits y luego imprímelo.\n",
    "\n",
    "El precódigo ya contiene el trabajo que realizaste para rellenar los valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "print(visits)\n",
    "\n",
    "#Resultado=============\n",
    "source\n",
    "context     52032\n",
    "email       13953\n",
    "other      133834\n",
    "undef         181\n",
    "Name: user_id, dtype: int64\n",
    "\n",
    "#La mayor fuente de tráfico es aparentemente \"other\" (otros). Misterioso…\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "A continuación, determina el número de visitas en las que se realizó una compra para cada fuente, calculando la suma de la columna 'purchase' para cada grupo de fuente. Posteriormente, asigna los resultados a la variable purchases e imprímelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "print(purchases)\n",
    "\n",
    "#Resultado======================\n",
    "source\n",
    "context    3029\n",
    "email      1021\n",
    "other      8041\n",
    "undef        12\n",
    "Name: purchase, dtype: int64\n",
    "\n",
    "#\"Otros\" también se las arregló para conseguir el mayor número de compras.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Calcula la tasa de conversión para cada fuente de tráfico, guarda los resultados en conversion, e imprímelos. La tasa de conversión es la proporción de visitas en las que se realizó una compra. El precódigo contiene las visitas y compras de tu trabajo previo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "\n",
    "conversion = purchases / visits\n",
    "print(conversion)\n",
    "\n",
    "#Resultado================\n",
    "source\n",
    "context    0.058214\n",
    "email      0.073174\n",
    "other      0.060082\n",
    "undef      0.066298\n",
    "dtype: float64\n",
    "\n",
    "#Aunque \"otros\" tiene más compras en general, parece que el correo electrónico tiene la mejor tasa de conversión. En unas pocas líneas de código, has conseguido calcular la métrica más importante del marketing.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rellenar valores ausentes cuantitativos**\n",
    "\n",
    "En esta lección usarás este conjunto de datos para aprender a tratar los datos cuantitativos ausentes, con el objetivo de comparar el tiempo promedio que pasan en el sitio web los usuarios y las usuarias de dispositivos móviles y de escritorio.\n",
    "\n",
    "Hemos guardado el archivo en la carpeta /datasets con el nombre web_analytics_data.csv. Carga los datos en la variable analytics_data e imprime las 10 primeras líneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "print(analytics_data.head(10))\n",
    "print(\"=================================\")\n",
    "analytics_data.info()\n",
    "\n",
    "#Resultado======================================================\n",
    "      user_id device_type   age    time\n",
    "0  7141786820     desktop  33.0  2127.0\n",
    "1  5644686960      mobile  30.0    35.0\n",
    "2  1914055396     desktop  25.0     NaN\n",
    "3  4099355752     desktop  25.0  2123.0\n",
    "4  6032477554     desktop  27.0    59.0\n",
    "5  5872473344      mobile  27.0     NaN\n",
    "6  7977025176      mobile   NaN     NaN\n",
    "7  3512872755     desktop  40.0    65.0\n",
    "8  1827368713     desktop  37.0     NaN\n",
    "9  8688870165     desktop  36.0  2124.0\n",
    "=================================\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 100000 entries, 0 to 99999\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count   Dtype  \n",
    "---  ------       --------------   -----  \n",
    " 0   user_id      100000 non-null  int64  \n",
    " 1   device_type  100000 non-null  object \n",
    " 2   age          94228 non-null   float64\n",
    " 3   time         75411 non-null   float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 3.1+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cuándo usar la media o la mediana?**\n",
    "\n",
    "Para decidir si la media o la mediana es un valor más representativo, podemos seguir estos pasos:\n",
    "1. Determina si los datos tienen valores atípicos significativos.\n",
    "2. Si no hay valores atípicos significativos, calcula la media utilizando el método mean().\n",
    "3. Si tus datos tienen valores atípicos significativos, calcula la mediana utilizando el método median().\n",
    "4. Reemplaza los valores ausentes con la media o la mediana utilizando el método fillna().\n",
    "\n",
    "Como no hay valores atípicos importantes en los datos, podemos utilizar la media como valor representativo tanto para 'age' como para 'time'. En el siguiente código, calculamos la edad promedio y la guardamos en una variable llamada age_avg, luego la usamos para completar los valores ausentes de 'age':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "print(\"Mean age:\", age_avg)\n",
    "\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "#Resultado ======================\n",
    "Mean age: 32.48966336969903\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Recuerda que queremos comparar el tiempo promedio que pasan en el sitio web las personas que utilizan dispositivos móviles y de escritorio, luego usaremos esos tiempos promedio para rellenar los valores ausentes.\n",
    "\n",
    "Comienza dividiendo los datos en dos DataFrames: uno para visitas desde dispositivos de escritorio y otro para visitas desde dispositivos móviles. Asigna las visitas de escritorio a una variable llamada desktop_data y las visitas móviles a otra variable llamada mobile_data.\n",
    "\n",
    "El precódigo ya lee los datos y rellena los valores ausentes de 'age'. Este también llama a info() por ti después de crear tus DataFrames filtrados para que puedas ver cuántos valores ausentes hay para cada dispositivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[ analytics_data['device_type'] == 'desktop']\n",
    "mobile_data = analytics_data[ analytics_data['device_type'] == 'mobile' ]\n",
    "\n",
    "desktop_data.info()\n",
    "print()\n",
    "mobile_data.info()\n",
    "\n",
    "#Resultado=======================\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 73764 entries, 0 to 99999\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      73764 non-null  int64  \n",
    " 1   device_type  73764 non-null  object \n",
    " 2   age          73764 non-null  float64\n",
    " 3   time         61588 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 2.8+ MB\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 26236 entries, 1 to 99997\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      26236 non-null  int64  \n",
    " 1   device_type  26236 non-null  object \n",
    " 2   age          26236 non-null  float64\n",
    " 3   time         13823 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 1.0+ MB\n",
    "\n",
    "#Buen trabajo con la partición exitosa de los datos. De acuerdo con info(), tanto los datos móviles como los de escritorio tienen valores ausentes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Ahora que los datos de escritorio y móviles están separados, calcula el tiempo medio de visita para cada dispositivo.\n",
    "\n",
    "Asigna la media del tiempo de visita de los usuarios de escritorio a una variable llamada desktop_avg y la media de los usuarios móviles a mobile_avg. \n",
    "\n",
    "El precódigo ya contiene el código para imprimir tus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg =  mobile_data['time'].mean()\n",
    "\n",
    "print(f\"Tiempo de escritorio promedio: {desktop_avg:.2f} segundos\")\n",
    "print(f\"Tiempo móvil promedio: {mobile_avg:.2f} segundos\")\n",
    "\n",
    "#Resultado==================\n",
    "Tiempo de escritorio promedio: 1741.87 segundos\n",
    "Tiempo móvil promedio: 41.16 segundos\n",
    "\n",
    "#¡Esa es una gran diferencia en el tiempo promedio! Tal vez los usuarios de escritorio tienden a dejar la página web abierta mientras hacen otras cosas, o tal vez los datos no se recopilan correctamente. No podemos decirlo con seguridad solo con la información que tenemos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Utiliza el tiempo promedio de visita de escritorio para rellenar los valores ausentes en la columna 'time' de desktop_data y el tiempo promedio de visita móvil para rellenarlos en mobile_data.\n",
    "\n",
    "El precódigo contiene tu trabajo de las tareas anteriores y llama a info() para que compruebes que los valores ausentes se hayan rellenado.\n",
    "\n",
    "Es posible que también hayas visto un SettingWithCopyWarning cuando ejecutaste tu código. No hay nada de que preocuparse en este caso, pero si deseas obtener más información al respecto consulta la documentación (materiales en inglés)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
