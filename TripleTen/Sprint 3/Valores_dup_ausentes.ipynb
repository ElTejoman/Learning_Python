{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Contar Valores ausentes**\n",
    "\n",
    "En las próximas lecciones, trabajaremos con un conjunto de datos de marketing de una empresa de comercio electrónico. Los datos están en un archivo CSV llamado visit_log.csv y cada fila representa una visita al sitio web de una empresa. Hay cuatro columnas:\n",
    "\n",
    "- 'user_id': identificador único para cada persona que visita el sitio web.\n",
    "- 'source': fuente de tráfico de la visita al sitio web. Aquí nos interesan tres categorías para la fuente:\n",
    "Visitas desde enlaces de marketing por correo electrónico: 'email'\n",
    "\n",
    "Visitas de anuncios contextuales en línea: 'context'\n",
    "\n",
    "Visitas de cualquier otra fuente: 'other'\n",
    "- 'email': dirección de correo electrónico encriptada asociada con la persona que visita el sitio.\n",
    "- 'purchase': indica si la persona compró algo en esa visita (1 en caso afirmativo, 0 en caso negativo).\n",
    "\n",
    "Tu objetivo es determinar la tasa de conversión para cada fuente, que es la proporción de visitas en las que se realizó una compra con respecto al número total de visitas en general. Comparar la tasa de conversión para cada fuente te permitirá determinar cuál de ellas genera la mayor cantidad de ventas.\n",
    "\n",
    "Pero antes de profundizar en los cálculos, necesitamos revisar el conjunto de datos para buscar valores ausentes y decidir qué hacer con ellos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BUSCAR VALORES AUSENTES**\n",
    "\n",
    "- **USAR EL MÉTODO INFO YA QUE TE DA LA INFORMACIÓN DE LOS NO SON AUSENTES, POR LO TANTO, TENDRÁS POR DESCARTE LOS AUSENTES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "print(df_logs.info())\n",
    "\n",
    "# RESULTADO =============================\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 200000 entries, 0 to 199999\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count   Dtype \n",
    "---  ------    --------------   ----- \n",
    " 0   user_id   200000 non-null  int64 \n",
    " 1   source    198326 non-null  object\n",
    " 2   email     13953 non-null   object\n",
    " 3   purchase  200000 non-null  int64 \n",
    "dtypes: int64(2), object(2)\n",
    "memory usage: 6.1+ MB\n",
    "None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **PERO TAMBIEN PUEDES UTILIZAR ISNULL().SUM()**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs.isnull().sum())\n",
    "\n",
    "#RESULTADO====================================================\n",
    "\n",
    "user_id          0\n",
    "source        1674\n",
    "email       186047\n",
    "purchase         0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contar los valores ausentes con value_counts()**\n",
    "\n",
    "En vez de sumar los valores obtenidos con isna(), podemos contar los valores ausentes con el método value_counts(). Al llamarlo en una sola columna (es decir, un Series), devuelve la cantidad de veces que cada valor único aparece en esa columna.\n",
    "\n",
    "Este método tiene un parámetro llamado dropna=, que se establece por defecto en True. Esto significa que value_counts() excluirá los valores None o NaN a menos que establezcas dropna=False.\n",
    "\n",
    "Utilicémoslo en la columna 'source' de nuestro DataFrame, asegurándonos de incluir los valores ausentes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs['source'].value_counts(dropna = False))\n",
    "\n",
    "#Resultado===================================================\n",
    "other      133834\n",
    "context     52032\n",
    "email       12279\n",
    "NaN          1674\n",
    "undef         181\n",
    "Name: source, dtype: int64\n",
    "\n",
    "#Ahora tenemos un recuento de todos esos valores de NaN.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, cuando imprimimos df_logs['source'].value_counts(dropna=False), la salida se ordena en orden descendente según el recuento de cada valor. Alternativamente, podemos ordenar la salida alfabéticamente según los nombres de los valores. Para hacerlo, podemos utilizar el método sort_index().\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "print(df_logs['source'].value_counts(dropna=False).sort_index())\n",
    "\n",
    "#RESULTADO =================================\n",
    "source\n",
    "context     52032\n",
    "email       12279\n",
    "other      133834\n",
    "undef         181\n",
    "NaN          1674\n",
    "Name: count, dtype: int64\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Resumen**\n",
    "\n",
    "Hay muchas formas de encontrar y contar valores ausentes en pandas. En esta lección aprendiste tres maneras:\n",
    "- Llamar a info() en un DataFrame.\n",
    "- Llamar a isna().sum() en un DataFrame o un Series.\n",
    "- Llamar a value_counts(dropna=False) en un Series.\n",
    "\n",
    "### Ejercicios\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Ahora aplica el método value_counts() a la columna 'email' y almacena el resultado en la variable email_values. Esta vez, no incluyas los valores ausentes en la salida. Imprime el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "email_values = df_logs['email'].value_counts()\n",
    "\n",
    "print(email_values)\n",
    "\n",
    "#Resultado============================\n",
    "\n",
    "4526cc437a    9\n",
    "410a2a3c23    9\n",
    "17c4fb26f9    8\n",
    "5a4c033120    7\n",
    "33f8a3d521    7\n",
    "             ..\n",
    "05d06bf263    1\n",
    "5e66f8634e    1\n",
    "35264deaa4    1\n",
    "fad76d6955    1\n",
    "7516495ced    1\n",
    "Name: email, Length: 6062, dtype: int64\n",
    "\n",
    "#Ahora vemos cómo quedan los valores de la columna 'email'. ¡Hay muchos! Parece que no es el mejor enfoque para examinar los valores ausentes en esta columna. Y sin embargo, ¡no está de más saberlo!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Ahora intentemos ordenar los resultados por índice en lugar de valores para ver si se añade algún significado a los valores de la columna 'email'. Vuelve a escribir la variable email_values utilizando la ordenación e imprime el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "email_values = df_logs['email'].value_counts()\n",
    "email_values = email_values.sort_index()\n",
    "\n",
    "print(email_values)\n",
    "\n",
    "#Resultado====================================\n",
    "000b6d0fb5    3\n",
    "000eb3c3df    4\n",
    "0017c0065d    4\n",
    "001c287e32    6\n",
    "002020511f    1\n",
    "             ..\n",
    "ff953ec581    1\n",
    "ffa51139e7    2\n",
    "ffcef1ce43    2\n",
    "ffe64c4d89    5\n",
    "fffc7f0482    1\n",
    "Name: email, Length: 6062, dtype: int64\n",
    "\n",
    "#Hasta ahora nada de información valiosa. Somos detectives de los datos. Es mejor intentarlo y fallar que no intentarlo del todo.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **FILTRAR DATAFRAMES CON NaNs**\n",
    "\n",
    "```python\n",
    "print(df_logs[df_logs['source'].isna()]) \n",
    "\n",
    "#Resultado\n",
    "                     user_id source       email  purchase\n",
    "22      1397217221    NaN  79ac569f0b         0\n",
    "49      5062457902    NaN  9ddce3a861         0\n",
    "171     6724868284    NaN  c0e48c7cf8         0\n",
    "258     3221384063    NaN  7fe8da1823         0\n",
    "379     7515782311    NaN  462462af10         0\n",
    "...            ...    ...         ...       ...\n",
    "199342  3439213943    NaN  7edda4e2a4         0\n",
    "199661  9473123762    NaN  3535509f51         0\n",
    "199689   722485056    NaN  470ffa3800         0\n",
    "199709  5950023506    NaN  0fb749d485         0\n",
    "199758  3747926428    NaN  604850216f         0\n",
    "\n",
    "[1674 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a desglosar esta línea de código:\n",
    "\n",
    "- Extraemos la columna 'source' utilizando df_logs['source']\n",
    "- A continuación, le aplicamos el método isna() para obtener una serie de booleanos que indican la ausencia de valores: df_logs['source'].isna()\n",
    "- Utilizamos esta serie de booleanos para filtrar el DataFrame original, extrayendo solamente las filas en las que 'source' no tiene valores ausentes.\n",
    "- Por último, imprimimos la tabla resultante.\n",
    "\n",
    "Otra opción es filtrar el DataFrame y extraer sólo las filas en las que no falte 'source'. El enfoque que utilizamos anteriormente funcionará con una única modificación menor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Múltiples condiciones de filtrado**\n",
    "\n",
    "Podemos filtrar un DataFrame a partir de múltiples condiciones. Por ejemplo, para crear un DataFrame que no tenga valores ausentes en la columna 'email' y solo el valor 'email' en la columna 'source', podemos emplear el siguiente código:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " print(df_logs[(~df_logs['email'].isna()) & (df_logs['source'] == 'email')])\n",
    "\n",
    " #Resultado ============================================\n",
    "                      user_id source       email  purchase\n",
    "1       5644686960  email  c129aa540a         0\n",
    "11      8623045648  email  d6d19c571c         0\n",
    "18      5739438900  email  19379ee49c         0\n",
    "19      7486955288  email  09c27794fa         0\n",
    "33      7298923004  email  1fe184ed73         0\n",
    "...            ...    ...         ...       ...\n",
    "199922  4075894991  email  2c9a202435         0\n",
    "199958  9794381984  email  85712b433a         0\n",
    "199970  3396355438  email  4bba3fde78         0\n",
    "199979  5008169696  email  e5128e15fd         0\n",
    "199989  9470921783  email  3977de6aaa         0\n",
    "\n",
    "[12279 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de filtrado anterior consta de dos partes:\n",
    "\n",
    "- (~df_logs['email'].isna()) devuelve una serie de booleanos donde True indica que no falta ningún valor en la columna 'email'.\n",
    "- (df_logs['source'] == 'email') devuelve una serie de booleanos, donde True indica que 'source' tiene 'email' como valor, y False indica lo contrario.\n",
    "- Comprobamos dos series de booleanos para ver dónde ambas condiciones devuelven True. Utilizamos el símbolo & para representar el operador lógico and. Las filas que cumplen ambas condiciones (es decir, que cumplen la primera condición y la segunda) se incluyen en el resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EJERCICIOS**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Anteriormente determinamos que la columna 'email' tiene 13 953 valores no ausentes. ¡Eso significa que más del 90% de los datos están ausentes! Filtra el DataFrame df_logs para que solo contenga filas donde no haya valores ausentes en la columna 'email'. Asigna el resultado filtrado a una variable llamada df_emails, luego imprime las primeras 10 filas.\n",
    "\n",
    "Para comprobar si una condición no es verdadera al filtrar un DataFrame, precede la condición con el carácter ~ (por ejemplo, df[~df.method()])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "df_emails = df_logs[~df_logs['email'].isna()]\n",
    "print(df_emails.head(10))\n",
    "\n",
    "#RESULTADO ======================================\n",
    "\n",
    "       user_id source       email  purchase\n",
    "1   5644686960  email  c129aa540a         0\n",
    "11  8623045648  email  d6d19c571c         0\n",
    "18  5739438900  email  19379ee49c         0\n",
    "19  7486955288  email  09c27794fa         0\n",
    "22  1397217221    NaN  79ac569f0b         0\n",
    "33  7298923004  email  1fe184ed73         0\n",
    "43  6034222291  email  fb58a27f03         0\n",
    "49  5062457902    NaN  9ddce3a861         0\n",
    "56  5690036640  email  a088a48182         0\n",
    "66  9963049355  email  9cc43ebd15         0 \n",
    "\n",
    "#Ahora solo tienes filas donde hay una dirección de correo electrónico asociada con la visita. ¡Combinar ~ con isna() es una excelente manera de filtrar las filas con valores ausentes!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "La columna 'source' muestra que muchas de estas visitas procedían de enlaces de correo electrónico de marketing. Pero también hay algunos valores NaN. Es posible que las visitas con una dirección de correo electrónico, pero sin un valor 'source', también provengan de enlaces de marketing por correo electrónico, pero que la fuente no se haya registrado.\n",
    "\n",
    "Comprueba si hay filas con valores ausentes en las columnas 'source' y 'email'. Si no hay ninguna fila en la que ambas condiciones sean verdaderas, entonces es una buena señal de que los valores ausentes en la columna 'source' deberían ser 'email'.\n",
    "\n",
    "Filtra df_logs en la condición donde las columnas 'email' y 'source' tienen valores ausentes. Asigna el resultado a una variable llamada df_emails y luego imprímelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "df_emails = df_logs[df_logs['email'].isna() & df_logs['source'].isna()]\n",
    "print(df_emails)\n",
    "\n",
    "#Resultado =======================================\n",
    "\n",
    "Empty DataFrame\n",
    "Columns: [user_id, source, email, purchase]\n",
    "Index: []\n",
    "\n",
    "#¡El DataFrame filtrado está vacío! Eso significa que no hay filas en las que 'source' y 'email' tengan valores ausentes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rellenar los valores categóricos ausentes**\n",
    "\n",
    "Los valores NaN en la columna 'email' sustituyen a las direcciones de correo electrónico de los usuarios y las usuarias que no se suscribieron al boletín de la tienda. Ya que no hay forma de averiguar sus direcciones de correo electrónico, no podemos rellenar manualmente los valores ausentes con datos significativos.\n",
    "\n",
    "Pero podemos rellenarlos con un valor por defecto para representar los correos electrónicos ausentes. Sustituyamos los valores ausentes en la columna 'email' por la cadena vacía '' como valor por defecto.\n",
    "\n",
    "- Utiliza el método fillna() para sustituir los valores ausentes en 'email' por cadenas vacías.\n",
    "- Imprime las cinco primeras filas del DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv')\n",
    "\n",
    "# Rellenar NaN en la columna 'email' con espacio en blanco\n",
    "df_logs['email'].fillna(value='', inplace=True)\n",
    "\n",
    "# Imprimir la cabecera del DataFrame después de reemplazar\n",
    "print(df_logs.head())\n",
    "\n",
    "#Resultado ========================\n",
    "\n",
    "      user_id   source       email  purchase\n",
    "0  7141786820    other                     0\n",
    "1  5644686960    email  c129aa540a         0\n",
    "2  1914055396  context                     0\n",
    "3  4099355752    other                     0\n",
    "4  6032477554  context                     1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **El parámetro keep_default_na=**\n",
    "\n",
    "Si observas los datos de texto sin procesar en el archivo visit_log.csv, encontrarás que los valores ausentes están representados por la ausencia de texto. En otras palabras, la ausencia de texto en visit_log.csv se interpreta como NaN. Consulta el archivo CSV en la pestaña de la lección.\n",
    "\n",
    "Pero podemos hacer que read_csv() lea la ausencia de texto como cadenas vacías en lugar de NaN, configurando el parámetro keep_default_na= en False. Probémoslo en nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "print(df_logs.head())\n",
    "print()\n",
    "df_logs.info()\n",
    "\n",
    "#Resultado ==========================\n",
    "\n",
    "      user_id   source       email  purchase\n",
    "0  7141786820    other                     0\n",
    "1  5644686960    email  c129aa540a         0\n",
    "2  1914055396  context                     0\n",
    "3  4099355752    other                     0\n",
    "4  6032477554  context                     1\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 200000 entries, 0 to 199999\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count   Dtype \n",
    "---  ------    --------------   ----- \n",
    " 0   user_id   200000 non-null  int64 \n",
    " 1   source    200000 non-null  object\n",
    " 2   email     200000 non-null  object\n",
    " 3   purchase  200000 non-null  int64 \n",
    "dtypes: int64(2), object(2)\n",
    "memory usage: 6.1+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Genial! ¡Ahora vamos a arreglar nuestros valores ausentes!\n",
    "- Utiliza replace() para reemplazar los valores ausentes en la columna 'source' por la cadena 'email'.\n",
    "- Verifica tu trabajo llamando al método unique() en la columna 'source' e imprime los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#ANTES EL CÓDIGO ERA ASI\n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "#df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "#df_sources = df_logs['source'].unique()\n",
    "#print(df_sources)\n",
    "\n",
    "#Resultado========================\n",
    "#['other' 'email' 'context' '' 'undef']\n",
    "\n",
    "```\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "\n",
    "df_logs['source'] = df_logs['source'].replace('','email')\n",
    "\n",
    "print(df_logs['source'].unique())\n",
    "\n",
    "Resultado==============\n",
    "['other' 'email' 'context' 'undef']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Para calcular la tasa de conversión de cada fuente de tráfico, primero determina cuántas visitas hubo de cada fuente.\n",
    "\n",
    "Para encontrar el número total de visitas de cada fuente de tráfico, utiliza groupby() para agrupar los datos por la columna 'source', luego cuenta el número de valores en la columna 'user_id' del DataFrame agrupado. Asigna el resultado en la variable visits y luego imprímelo.\n",
    "\n",
    "El precódigo ya contiene el trabajo que realizaste para rellenar los valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "print(visits)\n",
    "\n",
    "#Resultado=============\n",
    "source\n",
    "context     52032\n",
    "email       13953\n",
    "other      133834\n",
    "undef         181\n",
    "Name: user_id, dtype: int64\n",
    "\n",
    "#La mayor fuente de tráfico es aparentemente \"other\" (otros). Misterioso…\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "A continuación, determina el número de visitas en las que se realizó una compra para cada fuente, calculando la suma de la columna 'purchase' para cada grupo de fuente. Posteriormente, asigna los resultados a la variable purchases e imprímelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "print(purchases)\n",
    "\n",
    "#Resultado======================\n",
    "source\n",
    "context    3029\n",
    "email      1021\n",
    "other      8041\n",
    "undef        12\n",
    "Name: purchase, dtype: int64\n",
    "\n",
    "#\"Otros\" también se las arregló para conseguir el mayor número de compras.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Calcula la tasa de conversión para cada fuente de tráfico, guarda los resultados en conversion, e imprímelos. La tasa de conversión es la proporción de visitas en las que se realizó una compra. El precódigo contiene las visitas y compras de tu trabajo previo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "\n",
    "conversion = purchases / visits\n",
    "print(conversion)\n",
    "\n",
    "#Resultado================\n",
    "source\n",
    "context    0.058214\n",
    "email      0.073174\n",
    "other      0.060082\n",
    "undef      0.066298\n",
    "dtype: float64\n",
    "\n",
    "#Aunque \"otros\" tiene más compras en general, parece que el correo electrónico tiene la mejor tasa de conversión. En unas pocas líneas de código, has conseguido calcular la métrica más importante del marketing.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *===========================*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rellenar valores ausentes cuantitativos**\n",
    "\n",
    "En esta lección usarás este conjunto de datos para aprender a tratar los datos cuantitativos ausentes, con el objetivo de comparar el tiempo promedio que pasan en el sitio web los usuarios y las usuarias de dispositivos móviles y de escritorio.\n",
    "\n",
    "Hemos guardado el archivo en la carpeta /datasets con el nombre web_analytics_data.csv. Carga los datos en la variable analytics_data e imprime las 10 primeras líneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "print(analytics_data.head(10))\n",
    "print(\"=================================\")\n",
    "analytics_data.info()\n",
    "\n",
    "#Resultado======================================================\n",
    "      user_id device_type   age    time\n",
    "0  7141786820     desktop  33.0  2127.0\n",
    "1  5644686960      mobile  30.0    35.0\n",
    "2  1914055396     desktop  25.0     NaN\n",
    "3  4099355752     desktop  25.0  2123.0\n",
    "4  6032477554     desktop  27.0    59.0\n",
    "5  5872473344      mobile  27.0     NaN\n",
    "6  7977025176      mobile   NaN     NaN\n",
    "7  3512872755     desktop  40.0    65.0\n",
    "8  1827368713     desktop  37.0     NaN\n",
    "9  8688870165     desktop  36.0  2124.0\n",
    "=================================\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 100000 entries, 0 to 99999\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count   Dtype  \n",
    "---  ------       --------------   -----  \n",
    " 0   user_id      100000 non-null  int64  \n",
    " 1   device_type  100000 non-null  object \n",
    " 2   age          94228 non-null   float64\n",
    " 3   time         75411 non-null   float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 3.1+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cuándo usar la media o la mediana?**\n",
    "\n",
    "Para decidir si la media o la mediana es un valor más representativo, podemos seguir estos pasos:\n",
    "1. Determina si los datos tienen valores atípicos significativos.\n",
    "2. Si no hay valores atípicos significativos, calcula la media utilizando el método mean().\n",
    "3. Si tus datos tienen valores atípicos significativos, calcula la mediana utilizando el método median().\n",
    "4. Reemplaza los valores ausentes con la media o la mediana utilizando el método fillna().\n",
    "\n",
    "Como no hay valores atípicos importantes en los datos, podemos utilizar la media como valor representativo tanto para 'age' como para 'time'. En el siguiente código, calculamos la edad promedio y la guardamos en una variable llamada age_avg, luego la usamos para completar los valores ausentes de 'age':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "print(\"Mean age:\", age_avg)\n",
    "\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "#Resultado ======================\n",
    "Mean age: 32.48966336969903\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Recuerda que queremos comparar el tiempo promedio que pasan en el sitio web las personas que utilizan dispositivos móviles y de escritorio, luego usaremos esos tiempos promedio para rellenar los valores ausentes.\n",
    "\n",
    "Comienza dividiendo los datos en dos DataFrames: uno para visitas desde dispositivos de escritorio y otro para visitas desde dispositivos móviles. Asigna las visitas de escritorio a una variable llamada desktop_data y las visitas móviles a otra variable llamada mobile_data.\n",
    "\n",
    "El precódigo ya lee los datos y rellena los valores ausentes de 'age'. Este también llama a info() por ti después de crear tus DataFrames filtrados para que puedas ver cuántos valores ausentes hay para cada dispositivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[ analytics_data['device_type'] == 'desktop']\n",
    "mobile_data = analytics_data[ analytics_data['device_type'] == 'mobile' ]\n",
    "\n",
    "desktop_data.info()\n",
    "print()\n",
    "mobile_data.info()\n",
    "\n",
    "#Resultado=======================\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 73764 entries, 0 to 99999\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      73764 non-null  int64  \n",
    " 1   device_type  73764 non-null  object \n",
    " 2   age          73764 non-null  float64\n",
    " 3   time         61588 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 2.8+ MB\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 26236 entries, 1 to 99997\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      26236 non-null  int64  \n",
    " 1   device_type  26236 non-null  object \n",
    " 2   age          26236 non-null  float64\n",
    " 3   time         13823 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 1.0+ MB\n",
    "\n",
    "#Buen trabajo con la partición exitosa de los datos. De acuerdo con info(), tanto los datos móviles como los de escritorio tienen valores ausentes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Ahora que los datos de escritorio y móviles están separados, calcula el tiempo medio de visita para cada dispositivo.\n",
    "\n",
    "Asigna la media del tiempo de visita de los usuarios de escritorio a una variable llamada desktop_avg y la media de los usuarios móviles a mobile_avg. \n",
    "\n",
    "El precódigo ya contiene el código para imprimir tus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg =  mobile_data['time'].mean()\n",
    "\n",
    "print(f\"Tiempo de escritorio promedio: {desktop_avg:.2f} segundos\")\n",
    "print(f\"Tiempo móvil promedio: {mobile_avg:.2f} segundos\")\n",
    "\n",
    "#Resultado==================\n",
    "Tiempo de escritorio promedio: 1741.87 segundos\n",
    "Tiempo móvil promedio: 41.16 segundos\n",
    "\n",
    "#¡Esa es una gran diferencia en el tiempo promedio! Tal vez los usuarios de escritorio tienden a dejar la página web abierta mientras hacen otras cosas, o tal vez los datos no se recopilan correctamente. No podemos decirlo con seguridad solo con la información que tenemos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Utiliza el tiempo promedio de visita de escritorio para rellenar los valores ausentes en la columna 'time' de desktop_data y el tiempo promedio de visita móvil para rellenarlos en mobile_data.\n",
    "\n",
    "El precódigo contiene tu trabajo de las tareas anteriores y llama a info() para que compruebes que los valores ausentes se hayan rellenado.\n",
    "\n",
    "Es posible que también hayas visto un SettingWithCopyWarning cuando ejecutaste tu código. No hay nada de que preocuparse en este caso, pero si deseas obtener más información al respecto consulta la documentación (materiales en inglés)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "analytics_data = pd.read_csv('/datasets/web_analytics_data.csv')\n",
    "\n",
    "age_avg = analytics_data['age'].mean()\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data =  analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg = mobile_data['time'].mean()\n",
    "\n",
    "desktop_data['time']= desktop_data ['time'].fillna(desktop_avg)\n",
    "mobile_data['time']= mobile_data ['time'].fillna(mobile_avg)\n",
    "\n",
    "# esto comprobará si tienes algún valor ausente\n",
    "desktop_data.info()\n",
    "print()\n",
    "mobile_data.info()\n",
    "\n",
    "#Resultado============================\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 73764 entries, 0 to 99999\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      73764 non-null  int64  \n",
    " 1   device_type  73764 non-null  object \n",
    " 2   age          73764 non-null  float64\n",
    " 3   time         73764 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 2.8+ MB\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 26236 entries, 1 to 99997\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype  \n",
    "---  ------       --------------  -----  \n",
    " 0   user_id      26236 non-null  int64  \n",
    " 1   device_type  26236 non-null  object \n",
    " 2   age          26236 non-null  float64\n",
    " 3   time         26236 non-null  float64\n",
    "dtypes: float64(2), int64(1), object(1)\n",
    "memory usage: 1.0+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **========================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **========================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gestión de duplicados**\n",
    "\n",
    "### **Buscar duplicados a mano**\n",
    "\n",
    "El análisis que realizaste previamente sobre las fuentes de tráfico para el sitio de comercio electrónico online generó más preguntas en el equipo a cargo de atraer nuevos clientes. Quieren saber si hay una marca popular de teléfonos móviles que no esté suficientemente representada en el sitio web, así como estadísticas que comprueben qué modelos de teléfonos les interesan más a la clientela.\n",
    "\n",
    "Para empezar, quieren que averigües cuántas tiendas ya están vendiendo ciertos teléfonos en un mercado online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "\n",
    "print(df_stock.head(5))\n",
    "\n",
    "#Resultado=========================\n",
    "          id                     item  count\n",
    "0  100480924     Apple iPhone Xr 64gb     10\n",
    "1  100480924     Apple iPhone Xr 64GB     19\n",
    "2  100480959     Xiaomi Redmi 6A 16GB     44\n",
    "3  100480975          HUAWEI P30 lite     38\n",
    "4  100480988  Samsung Galaxy A30 32GB     49\n",
    "\n",
    "#En el caso del iPhone Xr 64 GB de Apple, solo debería haber una fila de datos y el recuento en esa fila debería ser 29. ¿Qué pasa si los datos de algunos de los otros teléfonos también están duplicados en otra parte de la tabla? Necesitamos poder analizar todo el conjunto de datos a la vez, en lugar de esperar encontrar duplicados leyendo una copia impresa de los datos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Revisión:** encontrar datos duplicados\n",
    "\n",
    "Hay dos técnicas que funcionan para encontrar datos duplicados:\n",
    "\n",
    "## **Técnica 1**\n",
    "\n",
    "Podemos utilizar el método duplicated() junto con sum() para obtener el número de valores duplicados en una sola columna o filas duplicadas en un DataFrame. Recuerda que si llamas a duplicated() sin utilizar sum(), se imprimirá una serie booleana tan larga como el DataFrame, con True donde hay un duplicado y False donde no lo hay. Ejecuta el siguiente código para ver un ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col_1': ['A', 'B', 'A', 'A'], 'col_2': [1, 2, 2, 1]})\n",
    "\n",
    "print('Así es como se ve el dataset:')\n",
    "print(df)\n",
    "print('Así es como se ve una serie booleana devuelta:')\n",
    "print(df.duplicated())\n",
    "print('Así se ve el resultado de duplicated() con sum():')\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "#Resultado ======================================\n",
    "Así es como se ve el dataset:\n",
    "    col_1  col_2\n",
    "0     A      1\n",
    "1     B      2\n",
    "2     A      2\n",
    "3     A      1\n",
    "\n",
    "Así es como se ve una serie booleana devuelta:\n",
    "0    False\n",
    "1    False\n",
    "```\n",
    "\n",
    "Por lo tanto, para comprobar la presencia de duplicados, utiliza el método duplicated() seguido del método sum(). Por cierto, puedes visualizar los duplicados mediante un simple filtrado:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col_1': ['A', 'B', 'A', 'A'], 'col_2': [1, 2, 2, 1]})\n",
    "\n",
    "print(df[df.duplicated()])\n",
    "\n",
    "#Resultado====================================\n",
    "    col_1  col_2\n",
    "3     A      1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Técnica 2**\n",
    "\n",
    "Llama al método value_counts(). Este método identifica todos los valores unívocos en una columna y calcula cuántas veces aparece cada uno. Podemos aplicar este método a los Series para obtener los pares valor-frecuencia en orden descendente. Las entradas que se duplican con más frecuencia se encuentran en la parte superior de la lista. A continuación te mostramos un ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col_1': ['A', 'B', 'A', 'A'], 'col_2': [1, 2, 2, 1]})\n",
    "\n",
    "print('Así es como se ve el dataset:')\n",
    "print(df)\n",
    "print()\n",
    "print('Este es el resultado de la llamada al método value_counts() para col_1:')\n",
    "print(df['col_1'].value_counts())\n",
    "\n",
    "#Resultado=================================\n",
    "Así es como se ve el dataset:\n",
    "  col_1  col_2\n",
    "0     A      1\n",
    "1     B      2\n",
    "2     A      2\n",
    "3     A      1\n",
    "\n",
    "Este es el resultado de la llamada al método value_counts() para col_1:\n",
    "A    3\n",
    "B    1\n",
    "Name: col_1, dtype: int64\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de duplicados\n",
    "\n",
    "Como ya aprendimos en el sprint de Python Básico, las filas completamente duplicadas, como la primera y la última fila del DataFrame del ejemplo anterior, se pueden tratar utilizando el método drop_duplicates():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col_1': ['A', 'B', 'A', 'A'], 'col_2': [1, 2, 2, 1]})\n",
    "\n",
    "print('Dataset original:')\n",
    "print(df)\n",
    "print()\n",
    "print('Dataset con duplicados eliminados:')\n",
    "print(df.drop_duplicates())\n",
    "\n",
    "#Resultado =====================================\n",
    "\n",
    "Dataset original:\n",
    "  col_1  col_2\n",
    "0     A      1\n",
    "1     B      2\n",
    "2     A      2\n",
    "3     A      1\n",
    "\n",
    "Dataset con duplicados eliminados:\n",
    "  col_1  col_2\n",
    "0     A      1\n",
    "1     B      2\n",
    "2     A      2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo deseas considerar duplicados en una (o algunas) de las columnas en lugar de filas completamente duplicadas, puedes usar el parámetro subset=. Pásale el nombre de la columna (o la lista de nombres de columna) donde deseas buscar duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_1  col_2\n",
      "0     A      1\n",
      "1     B      2\n",
      "2     A      2\n",
      "3     A      1\n",
      "\n",
      "  col_1  col_2\n",
      "0     A      1\n",
      "1     B      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'col_1': ['A', 'B', 'A', 'A'], 'col_2': [1, 2, 2, 1]})\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df.drop_duplicates(subset='col_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero la naturaleza de los datos duplicados de nuetra tabla original es distinta. Entonces la analizaremos de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "print(stock['item'].value_counts())\n",
    "\n",
    "#Resultado ===================================\n",
    "Apple iPhone Xr 64gb       1\n",
    "Apple iPhone Xr 64GB       1\n",
    "Xiaomi Redmi 6A 16GB       1\n",
    "HUAWEI P30 lite            1\n",
    "Samsung Galaxy A30 32GB    1\n",
    "Samsung Galaxy A30 32gb    1\n",
    "Honor 8X 64GB              1\n",
    "Name: item, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos entradas para el Samsung Galaxy y el iPhone de Apple. La única diferencia entre las dos entradas para ambos teléfonos es gb frente a GB. En realidad son duplicados, pero Python no los reconoce como tales porque las cadenas no son idénticas.\n",
    "\n",
    "La forma más sencilla de manejar entradas duplicadas como estas es hacer que todas las letras de las cadenas estén en minúsculas, utilizando el método lower(). A continuación te mostramos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col_1 original en el dataset:\n",
      "0    A\n",
      "1    B\n",
      "2    A\n",
      "3    A\n",
      "Name: col_1, dtype: object\n",
      "\n",
      "Dataset con valores reducidos en col_1\n",
      "0    a\n",
      "1    b\n",
      "2    a\n",
      "3    a\n",
      "Name: col_1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"col_1\": [\"A\", \"B\", \"A\", \"A\"], \"col_2\": [1, 2, 2, 1]})\n",
    "\n",
    "print(\"Col_1 original en el dataset:\")\n",
    "print(df[\"col_1\"])\n",
    "print()\n",
    "print(\"Dataset con valores reducidos en col_1\")\n",
    "print(df[\"col_1\"].str.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que después de df['col_1'], tenemos .str, que nos permite aplicar métodos de cadena directamente a la columna. Esto es exactamente lo que hay que hacer para poder aplicar el método lower() en el siguiente paso.\n",
    "\n",
    "Ten en cuenta que si quieres sustituir la columna original por una nueva en la que todas las letras estén en minúsculas, tendrás que volver a hacer la asignación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col_1  col_2\n",
      "0     a      1\n",
      "1     b      2\n",
      "2     a      2\n",
      "3     a      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"col_1\": [\"A\", \"B\", \"A\", \"A\"], \"col_2\": [1, 2, 2, 1]})\n",
    "\n",
    "# sustituir la columna col_1\n",
    "df[\"col_1\"] = df[\"col_1\"].str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que queramos comprobar el número de duplicados verdaderos en la columna 'col_1' después de transformar su contenido a minúsculas::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"col_1\": [\"A\", \"B\", \"A\", \"A\"], \"col_2\": [1, 2, 2, 1]})\n",
    "\n",
    "df[\"col_1\"] = df[\"col_1\"].str.lower()\n",
    "print(df[\"col_1\"].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se esperaba, obtuvimos 2 como salida. Esto se debe a que la tercera y la cuarta fila son idénticas a la primera.\n",
    "\n",
    "Si quieres cambiar las mayúsculas y minúsculas en solo una parte de la cadena, puedes usar el método replace() que aprendiste en el sprint de Python Básico. Por ejemplo, podrías cambiar todas las ocurrencias de 'gb' a 'GB' en la columna 'item' de los datos del teléfono:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "stock['item'] = stock['item'].str.replace('GB', 'gb')\n",
    "\n",
    "print(stock.head())\n",
    "\n",
    "#Resultado =============================\n",
    "\n",
    "                    id                     item  count\n",
    "0  100480924     Apple iPhone Xr 64gb     10\n",
    "1  100480924     Apple iPhone Xr 64gb     19\n",
    "2  100480959     Xiaomi Redmi 6A 16gb     44\n",
    "3  100480975          HUAWEI P30 lite     38\n",
    "4  100480988  Samsung Galaxy A30 32gb     49\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no estás seguro de cuál es el mejor enfoque, siempre puedes conservar la columna original y crear una nueva columna adicional, con las cadenas modificadas. Por ejemplo, podrías guardar el resultado de la sustitución en la columna 'item' en una nueva columna llamada 'item_modified':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "stock['item_modified'] = stock['item'].str.replace('GB', 'gb')\n",
    "\n",
    "print(stock.head())\n",
    "\n",
    "#Resultado ==============================\n",
    "                    id                     item  count            item_modified\n",
    "0  100480924     Apple iPhone Xr 64gb     10     Apple iPhone Xr 64gb\n",
    "1  100480924     Apple iPhone Xr 64gb     19     Apple iPhone Xr 64gb\n",
    "2  100480959     Xiaomi Redmi 6A 16gb     44     Xiaomi Redmi 6A 16gb\n",
    "3  100480975          HUAWEI P30 lite     38          HUAWEI P30 lite\n",
    "4  100480988  Samsung Galaxy A30 32gb     49  Samsung Galaxy A30 32gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "1. Cambia los nombres de los modelos de teléfonos a minúsculas usando el método str.lower() y guárdalos en una nueva columna llamada 'item_lowercase', pero conserva también la columna original 'item'.\n",
    "2. Imprime las primeras filas de la tabla actualizada y mira el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "\n",
    "df_stock['item_lowercase'] = df_stock['item'].str.lower()\n",
    "\n",
    "print(df_stock.head())\n",
    "\n",
    "#Resultado================================\n",
    "\n",
    "          id                     item  count           item_lowercase\n",
    "0  100480924     Apple iPhone Xr 64gb     10     apple iphone xr 64gb\n",
    "1  100480924     Apple iPhone Xr 64GB     19     apple iphone xr 64gb\n",
    "2  100480959     Xiaomi Redmi 6A 16GB     44     xiaomi redmi 6a 16gb\n",
    "3  100480975          HUAWEI P30 lite     38          huawei p30 lite\n",
    "4  100480988  Samsung Galaxy A30 32GB     49  samsung galaxy a30 32gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Utilizando tu recién creada columna 'item_lowercase' y el método sum(), calcula el número total de dos modelos de teléfono:\n",
    "\n",
    "1) 'apple iphone xr 64gb'\n",
    "2) 'samsung galaxy a30 32gb'\n",
    "\n",
    "Para contar el número de teléfonos Apple, filtra el DataFrame a partir de la columna 'item_lowercase' para incluir solo las filas con 'apple iphone xr 64gb' como valor. A continuación, extrae la columna 'count' del DataFrame filtrado y aplícale el método sum(). Almacena la cantidad total de teléfonos Apple en la variable apple.\n",
    "\n",
    "Para los teléfonos Samsung, sigue el mismo procedimiento con la única diferencia de que guardes el número total de teléfonos Samsung en la variable samsung.\n",
    "\n",
    "El precódigo ya contiene el código para imprimir tus resultados, no lo modifiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "df_stock['item_lowercase'] = df_stock['item'].str.lower()\n",
    "\n",
    "apple = df_stock[df_stock['item_lowercase'] == 'apple iphone xr 64gb']['count'].sum()\n",
    "samsung = df_stock[df_stock['item_lowercase'] == 'samsung galaxy a30 32gb']['count'].sum()\n",
    "\n",
    "print(\"Número total de teléfonos Apple:\", apple)\n",
    "print(\"Número total de teléfonos Samsung:\", samsung)\n",
    "\n",
    "#Resultado======================\n",
    "Número total de teléfonos Apple: 29\n",
    "Número total de teléfonos Samsung: 60\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Ahora elimina las filas con teléfonos duplicados llamando a drop_duplicates() en df_stock. Necesitamos eliminar filas únicamente en función de la columna item_lowercase', así que asegúrate de utilizarla como valor para el parámetro subset=.\n",
    "\n",
    "Recuerda que después de eliminar los duplicados, tenemos que llamar al método reset_index() con el parámetro drop=True. Esto nos permite arreglar la indexación y eliminar el índice antiguo.\n",
    "\n",
    "Por cierto, ¡puedes hacer todo esto con una sola línea de código! Puede ser un poco difícil, pero intenta encontrar la manera de hacerlo.\n",
    "\n",
    "El resultado final debería asignarse de nuevo a df_stock. Imprime las primeras filas del df_stock cuando hayas terminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "df_stock['item_lowercase'] = df_stock['item'].str.lower()\n",
    "\n",
    "df_stock = df_stock.drop_duplicates(subset = 'item_lowercase').reset_index(drop = True)\n",
    "print(df_stock)\n",
    "\n",
    "#Resultado=====================\n",
    "          id                     item  count           item_lowercase\n",
    "0  100480924     Apple iPhone Xr 64gb     10     apple iphone xr 64gb\n",
    "1  100480959     Xiaomi Redmi 6A 16GB     44     xiaomi redmi 6a 16gb\n",
    "2  100480975          HUAWEI P30 lite     38          huawei p30 lite\n",
    "3  100480988  Samsung Galaxy A30 32GB     49  samsung galaxy a30 32gb\n",
    "4  100481020            Honor 8X 64GB     64            honor 8x 64gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4**\n",
    "\n",
    "El precódigo incluye una línea que escribiste anteriormente para eliminar duplicados, por lo que ahora tenemos el DataFrame df_stock sin duplicados. Tu objetivo es establecer los valores correctos en la columna 'count' para las filas donde 'item' es 'Apple iPhone XR 64GB' y 'Samsung Galaxy A30 32GB'.\n",
    "\n",
    "Los valores que vas a establecer ya fueron calculados por ti previamente y están almacenados en las variables apple y samsung en el precódigo.\n",
    "\n",
    "La mejor forma de actualizar los valores de la columna 'count' es utilizar el atributo loc[] que puede reemplazar los valores en un lugar especificado.\n",
    "\n",
    "Revisemos el df_stock después de eliminar los duplicados para ilustrar cómo loc[] puede ayudarnos a actualizar los valores:\n",
    "\n",
    "```python\n",
    "                    id                     item  count           item_lowercase\n",
    "0  100480924     Apple iPhone Xr 64gb     10     apple iphone xr 64gb\n",
    "1  100480959     Xiaomi Redmi 6A 16GB     44     xiaomi redmi 6a 16gb\n",
    "2  100480975          HUAWEI P30 lite     38          huawei p30 lite\n",
    "3  100480988  Samsung Galaxy A30 32GB     49  samsung galaxy a30 32gb\n",
    "4  100481020            Honor 8X 64GB     64            honor 8x 64gb\n",
    "```\n",
    "Podemos utilizar loc[] para actualizar el valor de la primera fila (índice 0) y la columna 'count' del modelo Apple iPhone. Pasamos dos valores a loc[] para especificar el índice de la fila y el nombre de la columna, y luego utilizamos el signo = para establecer el valor deseado:\n",
    "\n",
    "```python\n",
    "df_stock.loc[0,'count'] = 33\n",
    "```\n",
    "En el ejemplo anterior, utilizamos el valor 33, pero en realidad queremos establecer el valor de la variable apple que previamente hemos calculado y guardado.\n",
    "\n",
    "Fue un ejemplo para el iPhone de Apple. El procedimiento para Samsung será el mismo, salvo que le pasaremos valores diferentes al atributo loc[].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "df_stock['item_lowercase'] = df_stock['item'].str.lower()\n",
    "\n",
    "apple = df_stock[df_stock['item_lowercase'] == 'apple iphone xr 64gb']['count'].sum()\n",
    "samsung = df_stock[df_stock['item_lowercase'] == 'samsung galaxy a30 32gb']['count'].sum()\n",
    "\n",
    "df_stock = df_stock.drop_duplicates(subset='item_lowercase').reset_index(drop=True)\n",
    "\n",
    "df_stock.loc[0, 'count'] = apple\n",
    "df_stock.loc[3, 'count'] = samsung\n",
    "\n",
    "print(df_stock)\n",
    "\n",
    "#Resultado===============================================================\n",
    "          id                     item  count           item_lowercase\n",
    "0  100480924     Apple iPhone Xr 64gb     10     apple iphone xr 64gb\n",
    "1  100480959     Xiaomi Redmi 6A 16GB     44     xiaomi redmi 6a 16gb\n",
    "2  100480975          HUAWEI P30 lite     38          huawei p30 lite\n",
    "3  100480988  Samsung Galaxy A30 32GB     49  samsung galaxy a30 32gb\n",
    "4  100481020            Honor 8X 64GB     64            honor 8x 64gb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el DataFrame:\n",
    "\n",
    "\n",
    "```python\n",
    "df_stock = pd.read_csv('/datasets/phone_stock.csv')\n",
    "Aquí se carga el DataFrame desde el archivo CSV proporcionado.\n",
    "```\n",
    "\n",
    "Crear una columna en minúsculas:\n",
    "\n",
    "\n",
    "```python\n",
    "df_stock['item_lowercase'] = df_stock['item'].str.lower()\n",
    "```\n",
    "\n",
    "Se agrega una nueva columna llamada 'item_lowercase', que contiene los nombres de los elementos en minúsculas. Esto facilita la búsqueda y comparación sin distinción entre mayúsculas y minúsculas.\n",
    "\n",
    "Calcular sumas para 'apple' y 'samsung':\n",
    "\n",
    "```python\n",
    "\n",
    "apple = df_stock[df_stock['item_lowercase'] == 'apple iphone xr 64gb']['count'].sum()\n",
    "samsung = df_stock[df_stock['item_lowercase'] == 'samsung galaxy a30 32gb']['count'].sum()\n",
    "```\n",
    "\n",
    "Se calcula la suma de la columna 'count' para los elementos 'apple iphone xr 64gb' y 'samsung galaxy a30 32gb'.\n",
    "\n",
    "Eliminar duplicados:\n",
    "\n",
    "\n",
    "```python\n",
    "df_stock = df_stock.drop_duplicates(subset='item_lowercase').reset_index(drop=True)\n",
    "\n",
    "```\n",
    "Los duplicados se eliminan basándose en la columna 'item_lowercase' y se reinician los índices para mantener la integridad del DataFrame.\n",
    "\n",
    "Asignar valores con loc:\n",
    "\n",
    "\n",
    "```python\n",
    "df_stock.loc[0, 'count'] = apple\n",
    "df_stock.loc[3, 'count'] = samsung\n",
    "```\n",
    "\n",
    "Usando loc, se asignan los valores calculados ('apple' y 'samsung') a las celdas específicas en la columna 'count'. En este caso, el índice 0 corresponde a 'apple' y el índice 3 corresponde a 'samsung'.\n",
    "\n",
    "Imprimir el DataFrame resultante:\n",
    "\n",
    "```python\n",
    "print(df_stock)\n",
    "```\n",
    "\n",
    "Finalmente, se imprime el DataFrame actualizado con los valores asignados para 'apple' y 'samsung'.\n",
    "\n",
    "**DE ESTA MANERA SE EXPLICA Y DETALLA EL PROCESO DEL ULTIMO EJERCICIO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exámen del Capítulo**\n",
    "\n",
    "**ejercicio 1**\n",
    "\n",
    "En cuanto al primer paso, vamos a ver las filas con los valores ausentes. Ya los hemos encontrado en la columna 'price' creando una serie de booleanos y guardándola en la variable mis_booleans.\n",
    "\n",
    "Ahora utiliza esta variable para filtrar el DataFrame original, extrayendo las filas con valores ausentes, y guarda el resultado del filtrado en la variable mis_rows. Muéstralo en la pantalla.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data.csv')\n",
    "mis_booleans = df['price'].isna()\n",
    "\n",
    "mis_rows = df[mis_booleans]\n",
    "print(mis_rows)\n",
    "\n",
    "#Resultado========================================\n",
    "    category      product  price\n",
    "7  hair care  conditioner    NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a rellenar un único valor ausente que hay. Para ello te pedimos:\n",
    "1. Agrupar por la columna 'category' y extraer la columna 'price'.\n",
    "2. Aplicar un método adecuado para calcular el valor del precio promedio de cada categoría y guardarlo en la variable avg_per_category.\n",
    "\n",
    "En la siguiente tarea, utilizarás este valor para sustituir el único valor ausente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data.csv')\n",
    "\n",
    "avg_per_category = df.groupby('category')['price'].mean()\n",
    "\n",
    "print(avg_per_category)\n",
    "\n",
    "#Resultado=====================\n",
    "category\n",
    "baby care    34.000000\n",
    "cosmetics    22.666667\n",
    "hair care    16.500000\n",
    "tbc           9.000000\n",
    "Name: price, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos casi listos para completar un único valor ausente que hay. Para ello te pedimos:\n",
    "\n",
    "1. Extrae el precio promedio para la categoría de nuestro interés (aquella a la que pertenece una fila con un valor ausente.) Es 'hair care'). Para hacerlo, indexa un Series a través de un número de índice y guárdalo en la variable mean_val. Nota: Si quieres encontrar un índice necesario, consulta el resultado del ejercicio anterior.\n",
    "\n",
    "2. Muestra mean_val.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data.csv')\n",
    "avg_per_category = df.groupby('category')['price'].mean()\n",
    "\n",
    "# Utiliza el índice conocido de 'hair care' para extraer el precio promedio\n",
    "mean_val = avg_per_category[2]\n",
    "\n",
    "print(mean_val)\n",
    "\n",
    "Resultado\n",
    "16.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que sustituir un valor único por un promedio de su categoría. Para hacerlo, puedes utilizar el atributo loc[] de Python. Para empezar, busca la fila que contiene el valor que quieres sustituir,\n",
    "\n",
    "    category      product  price\n",
    "7  hair care  conditioner    NaN\n",
    "\n",
    "A continuación, pasa el índice y el nombre de columna adecuados a loc[], y utiliza el signo = para establecer el valor deseado.\n",
    "Se puede obtener el índice y el nombre de columna a utilizar en loc[] examinando las filas que contienen el valor ausente.\n",
    "Muestra la variable df al final.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data.csv')\n",
    "avg_per_category = df.groupby('category')['price'].mean()\n",
    "\n",
    "mean_val = avg_per_category[2]\n",
    "\n",
    "df.loc[7, 'price'] = mean_val\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Resultado===============================================\n",
    "    category      product  price\n",
    "0  cosmetics      lipstic   25.0\n",
    "1  cosmetics      LIPSTIC   25.0\n",
    "2        tbc     pacifier    9.0\n",
    "3  hair care      shampoo   12.0\n",
    "4  baby care      diapers   34.0\n",
    "5  cosmetics       lotion   18.0\n",
    "6  hair care     hair gel   21.0\n",
    "7  hair care  conditioner   16.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inmediatamente observamos que 'lipstic' y 'LIPSTIC' aparecen en la columna como valores distintos. Para solucionarlo, recomendamos crear una nueva columna en la que todos los valores estén en minúsculas, para garantizar la coherencia. \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data_no_nans.csv')\n",
    "\n",
    "df['product'] = df['product'].str.lower()\n",
    "\n",
    "print(df['product'])\n",
    "\n",
    "#Resultado==================\n",
    "0        lipstic\n",
    "1        lipstic\n",
    "2       pacifier\n",
    "3        shampoo\n",
    "4        diapers\n",
    "5         lotion\n",
    "6       hair gel\n",
    "7    conditioner\n",
    "Name: product, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, hemos observado anteriormente que existe el valor 'tbc' en la columna 'category'. Así es como se ve esta fila:\n",
    "\n",
    "\n",
    "```python\n",
    "category    product     price\n",
    "1       tbc    pacifier     9.0\n",
    "```\n",
    "\n",
    "\n",
    "Vamos a utilizar el método replace() para establecer un valor adecuado. Está claro que 'pacifier' (chupete) como producto pertenece a la categoría 'baby care' que tenemos en nuestro conjunto de datos. Después del reemplazo, imprime el DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/products_data_no_nans_and_dupl.csv')\n",
    "\n",
    "df['category'] = df['category'].str.replace('tbc','baby care')\n",
    "print(df)\n",
    "\n",
    "#Resultado====================\n",
    "    category      product  price\n",
    "0  cosmetics      lipstic   25.0\n",
    "1  baby care     pacifier    9.0\n",
    "2  hair care      shampoo   12.0\n",
    "3  baby care      diapers   34.0\n",
    "4  cosmetics       lotion   18.0\n",
    "5  hair care     hair gel   21.0\n",
    "6  hair care  conditioner   16.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **=======================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FILTRADO DE DATOS**\n",
    "\n",
    "## **Indices en DataFrames y Series**\n",
    "\n",
    "### **Atributo index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=5, step=1)\n",
      "<class 'pandas.core.indexes.range.RangeIndex'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oceans = pd.Series([\"Pacific\", \"Atlantic\", \"Indian\", \"Southern\", \"Arctic\"])\n",
    "\n",
    "print(oceans.index)\n",
    "print(type(oceans.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos establecer el índice que queramos. Por ejemplo, vamos a establecer los valores de índice utilizando una lista de números enteros del 1 al 5 asignando esta lista de números al atributo index de oceans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oceans = pd.Series([\"Pacific\", \"Atlantic\", \"Indian\", \"Southern\", \"Arctic\"])\n",
    "\n",
    "oceans.index = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(oceans.index)\n",
    "print(type(oceans.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n este caso, nuestro índice es del tipo de datos Int64Index, que es un tipo general para un índice de valores enteros que no se generan a partir de un objeto range. No te preocupes sobre la gran cantidad de nuevos tipos de datos. No son más que tipos de índice que puedes mantener por defecto o establecer por tu cuenta.\n",
    "\n",
    "También podemos establecer el atributo index utilizando el parámetro index= en la llamada a Series(), lo cual es preferible si no queremos el índice predeterminado y no planeamos modificar el índice posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oceans = pd.Series(\n",
    "    [\"Pacific\", \"Atlantic\", \"Indian\", \"Southern\", \"Arctic\"], index=[1, 2, 3, 4, 5]\n",
    ")\n",
    "\n",
    "print(oceans.index)\n",
    "print(type(oceans.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a configurar nuestros valores de índice como cadenas y a comprobar qué tipo de datos obtenemos para el índice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     Pacific\n",
      "B    Atlantic\n",
      "C      Indian\n",
      "D    Southern\n",
      "E      Arctic\n",
      "dtype: object\n",
      "\n",
      "Index(['A', 'B', 'C', 'D', 'E'], dtype='object')\n",
      "<class 'pandas.core.indexes.base.Index'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oceans = pd.Series(\n",
    "    [\"Pacific\", \"Atlantic\", \"Indian\", \"Southern\", \"Arctic\"],\n",
    "    index=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    ")\n",
    "\n",
    "print(oceans)\n",
    "print()\n",
    "print(oceans.index)\n",
    "print(type(oceans.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Indexación mediante loc[]**\n",
    "\n",
    "- **Index (índice)**: un componente de un Series o DataFrame, accesible mediante el atributo index.\n",
    "- **Indexing (indexación)**: el proceso de acceder a los valores de un Series o DataFrame utilizando sus índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget-me-not\n",
      "            state                  flower                          insect\n",
      "state 1   Alabama                Camellia               Monarch butterfly\n",
      "state 2    Alaska           Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 3   Arizona  Saguaro cactus blossom          Two-tailed swallowtail\n",
      "state 4  Arkansas           Apple blossom              European honey bee\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "prueba = df.loc['state 2', 'flower']\n",
    "\n",
    "print(prueba)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European honey bee\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df.loc[\"state 4\", \"insect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         flower                          insect     state\n",
      "state 3  Saguaro cactus blossom          Two-tailed swallowtail   Arizona\n",
      "state 4           Apple blossom              European honey bee  Arkansas\n",
      "state 2           Forget-me-not  Four-spotted skimmer dragonfly    Alaska\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "\n",
    "prueba2 = df.loc[[\"state 3\", \"state 4\", \"state 2\"], [\"flower\", \"insect\", \"state\"]]\n",
    "\n",
    "print(prueba2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "practicar esta manera de utilizar loc[] para obtener solo las columnas 'flower' e 'insect' para Alabama y Arizona. Guarda el resultado en la variable filtered_df. Para obtener el índice que tienen Alabama y Arizona, consulta el DataFrame:\n",
    "\n",
    "```python\n",
    "            state                  flower                          insect\n",
    "state 1   Alabama                Camellia               Monarch butterfly\n",
    "state 2    Alaska           Forget-me-not  Four-spotted skimmer dragonfly\n",
    "state 3   Arizona  Saguaro cactus blossom          Two-tailed swallowtail\n",
    "state 4  Arkansas           Apple blossom              European honey bee\n",
    "\n",
    "```\n",
    "Tu código debería devolver otro DataFrame. Muestra filtered_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         flower                  insect\n",
      "state 1                Camellia       Monarch butterfly\n",
      "state 3  Saguaro cactus blossom  Two-tailed swallowtail\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "filtered_df = df.loc[[\"state 1\", \"state 3\"], [\"flower\", \"insect\"]]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 1                  Camellia\n",
      "state 2             Forget-me-not\n",
      "state 3    Saguaro cactus blossom\n",
      "Name: flower, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df.loc[\"state 1\":\"state 3\", \"flower\"])\n",
    "\n",
    "#CON RANGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera, puedes seleccionar múltiples columnas así como índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         flower                          insect\n",
      "state 1                Camellia               Monarch butterfly\n",
      "state 2           Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 3  Saguaro cactus blossom          Two-tailed swallowtail\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df.loc[\"state 1\":\"state 3\", \"flower\":\"insect\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, a practicar. Esta vez, utiliza loc[] para obtener solo la columna 'insect' para todos los estados, excepto Alabama. Tu código debería devolver un Series. Imprime el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 2    Four-spotted skimmer dragonfly\n",
      "state 3            Two-tailed swallowtail\n",
      "state 4                European honey bee\n",
      "Name: insect, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "df_modified = df.loc[\"state 2\":\"state 4\", \"insect\"]\n",
    "print(df_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Indexación mediante iloc[]**\n",
    "\n",
    "Mientras que loc[] utiliza el índice y las etiquetas de columnas para acceder a los elementos, iloc[] utiliza enteros para designar las posiciones de los elementos que necesitas obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            state                  flower                          insect\n",
      "state 1   Alabama                Camellia               Monarch butterfly\n",
      "state 2    Alaska           Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 3   Arizona  Saguaro cactus blossom          Two-tailed swallowtail\n",
      "state 4  Arkansas           Apple blossom              European honey bee\n",
      "\n",
      "European honey bee\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df.iloc[3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que con loc[], podemos acceder a múltiples filas y/o columnas con iloc[] pasándole listas de sus posiciones o utilizando el slicing. Así es como podemos conseguir el mismo resultado que obtenemos con\n",
    "\n",
    "df.loc[['state 1', 'state 3'], ['flower', 'insect']] utilizando iloc[]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            state                  flower                          insect\n",
      "state 1   Alabama                Camellia               Monarch butterfly\n",
      "state 2    Alaska           Forget-me-not  Four-spotted skimmer dragonfly\n",
      "state 3   Arizona  Saguaro cactus blossom          Two-tailed swallowtail\n",
      "state 4  Arkansas           Apple blossom              European honey bee\n",
      "\n",
      "                         flower                  insect\n",
      "state 1                Camellia       Monarch butterfly\n",
      "state 3  Saguaro cactus blossom  Two-tailed swallowtail\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df.iloc[[0, 2], 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cierto, también se puede utilizar la indexación negativa. Aquí tienes un ejemplo en el que se selecciona la última columna (que tiene un índice de Python -1) y las filas 1ª y 3ª (índices de Python 0 y 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 1         Monarch butterfly\n",
      "state 3    Two-tailed swallowtail\n",
      "Name: insect, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "\n",
    "print(df.iloc[[0, 2], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cambiar el índice de un DataFrame con el método set_index()**\n",
    "\n",
    "Dos maneras de establecer valores de índice:\n",
    "\n",
    "- Pasar los valores del índice al parámetro index= al crear un DataFrame o un Series.\n",
    "- Asignar los valores del índice al atributo index de un DataFrame o Series existente.\n",
    "\n",
    "En el caso de los DataFrames, existe otra forma de establecer los valores del índice mediante el método set_index(). Este método toma una columna existente de un DataFrame y reemplaza el índice con los valores de esa columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           state                          insect\n",
      "flower                                                          \n",
      "Camellia                 Alabama               Monarch butterfly\n",
      "Forget-me-not             Alaska  Four-spotted skimmer dragonfly\n",
      "Saguaro cactus blossom   Arizona          Two-tailed swallowtail\n",
      "Apple blossom           Arkansas              European honey bee\n",
      "\n",
      "Index(['Camellia', 'Forget-me-not', 'Saguaro cactus blossom', 'Apple blossom'], dtype='object', name='flower')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "df = df.set_index(\"flower\")  # reemplazar el índice\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no quieres que el índice tenga un nombre, puedes eliminarlo estableciendo el atributo index_name de un DataFrame a None. Así es como puedes hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          flower                          insect\n",
      "Alabama                 Camellia               Monarch butterfly\n",
      "Alaska             Forget-me-not  Four-spotted skimmer dragonfly\n",
      "Arizona   Saguaro cactus blossom          Two-tailed swallowtail\n",
      "Arkansas           Apple blossom              European honey bee\n",
      "\n",
      "Index(['Alabama', 'Alaska', 'Arizona', 'Arkansas'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "df = df.set_index(\"state\")\n",
    "\n",
    "df.index.name = None\n",
    "print(df)\n",
    "print()\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Utiliza loc[] para extraer las flores de Alabama, Alaska y Arizona, y guarda el resultado en la variable flowers. Luego, muestra esta variable.\n",
    "\n",
    "El precódigo ya crea el DataFrame por ti y establece la columna 'state' como índice, así que asegúrate de usar los nombres de los estados como valores del índice en loc[]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Alabama                  Camellia\n",
      "Alaska              Forget-me-not\n",
      "Arizona    Saguaro cactus blossom\n",
      "Name: flower, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "df = df.set_index(\"state\")\n",
    "\n",
    "\n",
    "flowers = df.loc[\"Alabama\":\"Arizona\", \"flower\"]\n",
    "print(flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Ahora utiliza iloc[] para indexar exactamente la misma parte del DataFrame que usaste en la última tarea. Igual que hicimos antes, guarda el resultado en la variable flowers e imprímela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Alabama                  Camellia\n",
      "Alaska              Forget-me-not\n",
      "Arizona    Saguaro cactus blossom\n",
      "Name: flower, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\"]\n",
    "flowers = [\"Camellia\", \"Forget-me-not\", \"Saguaro cactus blossom\", \"Apple blossom\"]\n",
    "insects = [\n",
    "    \"Monarch butterfly\",\n",
    "    \"Four-spotted skimmer dragonfly\",\n",
    "    \"Two-tailed swallowtail\",\n",
    "    \"European honey bee\",\n",
    "]\n",
    "index = [\"state 1\", \"state 2\", \"state 3\", \"state 4\"]\n",
    "\n",
    "df = pd.DataFrame({\"state\": states, \"flower\": flowers, \"insect\": insects}, index=index)\n",
    "df = df.set_index(\"state\")\n",
    "\n",
    "flowers = df.iloc[0:3, 0]\n",
    "print(flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **=========================**\n",
    "\n",
    "### **Cambiar el índice de un DataFrame con el método set_index()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrar utilizando dos nuevos métodos de pandas:\n",
    "\n",
    "- isin(), que comprueba la presencia.\n",
    "- query(), que te permite filtrar mediante consultas de cadena personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploracion dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.info())\n",
    "\n",
    "# Resultado ==========================================\n",
    "\n",
    "                       name platform  year_of_release         genre publisher  \\\n",
    "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
    "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
    "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
    "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
    "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
    "\n",
    "  developer  na_sales  eu_sales  jp_sales  critic_score  user_score  \n",
    "0  Nintendo     41.36     28.96      3.77          76.0         8.0  \n",
    "1       NaN     29.08      3.58      6.81           NaN         NaN  \n",
    "2  Nintendo     15.68     12.76      3.79          82.0         8.3  \n",
    "3  Nintendo     15.61     10.93      3.28          80.0         8.0  \n",
    "4       NaN     11.27      8.89     10.22           NaN         NaN  \n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 16717 entries, 0 to 16716\n",
    "Data columns (total 11 columns):\n",
    " #   Column           Non-Null Count  Dtype  \n",
    "---  ------           --------------  -----  \n",
    " 0   name             16717 non-null  object \n",
    " 1   platform         16717 non-null  object \n",
    " 2   year_of_release  16448 non-null  float64\n",
    " 3   genre            16717 non-null  object \n",
    " 4   publisher        16663 non-null  object \n",
    " 5   developer        10096 non-null  object \n",
    " 6   na_sales         16717 non-null  float64\n",
    " 7   eu_sales         16717 non-null  float64\n",
    " 8   jp_sales         16717 non-null  float64\n",
    " 9   critic_score     8137 non-null   float64\n",
    " 10  user_score       7590 non-null   float64\n",
    "dtypes: float64(6), object(5)\n",
    "memory usage: 1.4+ MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado con consultas de cadena y el método query()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "mask = df['jp_sales'] >= 1\n",
    "print(df[mask][['name', 'jp_sales']])\n",
    "\n",
    "#RESULTADO =======================================\n",
    "\n",
    "                                             name  jp_sales\n",
    "0                                      Wii Sports      3.77\n",
    "1                               Super Mario Bros.      6.81\n",
    "2                                  Mario Kart Wii      3.79\n",
    "3                               Wii Sports Resort      3.28\n",
    "4                        Pokemon Red/Pokemon Blue     10.22\n",
    "...                                           ...       ...\n",
    "1970                  Tag Team Match M.U.S.C.L.E.      1.05\n",
    "1971                            Derby Stallion 96      1.04\n",
    "1972                             Adventure Island      1.05\n",
    "2051    Oshare Majo Love and Berry: DS Collection      1.01\n",
    "2065  Jissen Pachi-Slot Hisshouhou: Hokuto no Ken      1.00\n",
    "\n",
    "[243 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterior, la variable mask contiene una serie con valores True y False. True indica que un valor dado de la columna 'jp_sales' tiene unas ventas iguales o superiores a un millón de dólares, mientras que False corresponde a unas ventas inferiores a un millón de dólares.\n",
    "\n",
    "A continuación, utilizamos esta máscara para filtrar el DataFrame original con df[mask] y seleccionar dos columnas de nuestro interés: ['name', 'jp_sales'].\n",
    "\n",
    "Resulta que hay más de 16 000 juegos en el conjunto de datos y solo 243 alcanzaron un millón en ventas en Japón. A efectos de la brevedad, solo veremos las columnas 'name' y 'jp_sales'. Por supuesto, podríamos haber omitido la creación de la variable mask y simplemente poner la expresión de máscara directamente en nuestra línea de código de filtrado.\n",
    "\n",
    "Podemos realizar este mismo filtrado utilizando el método query().\n",
    "\n",
    "Este método es llamado en un DataFrame y requiere una cadena como entrada. La cadena representa la consulta que quieres hacer en tu DataFrame, lo que básicamente significa que le dice a Python qué filas debe filtrar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/datasets/vg_sales.csv\")\n",
    "\n",
    "print(df.query(\"jp_sales > 1\")[[\"name\", \"jp_sales\"]])\n",
    "\n",
    "#RESULTADO =============================\n",
    "\n",
    "                                           name  jp_sales\n",
    "0                                    Wii Sports      3.77\n",
    "1                             Super Mario Bros.      6.81\n",
    "2                                Mario Kart Wii      3.79\n",
    "3                             Wii Sports Resort      3.28\n",
    "4                      Pokemon Red/Pokemon Blue     10.22\n",
    "...                                         ...       ...\n",
    "1885                              Densha De Go!      1.02\n",
    "1970                Tag Team Match M.U.S.C.L.E.      1.05\n",
    "1971                          Derby Stallion 96      1.04\n",
    "1972                           Adventure Island      1.05\n",
    "2051  Oshare Majo Love and Berry: DS Collection      1.01\n",
    "\n",
    "[239 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OTRO EJEMPLO**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "print(df.query(\"publisher == 'Nintendo'\")[['name', 'publisher']].head())\n",
    "\n",
    "#RESULTADO===============================\n",
    "\n",
    "                       name publisher\n",
    "0                Wii Sports  Nintendo\n",
    "1         Super Mario Bros.  Nintendo\n",
    "2            Mario Kart Wii  Nintendo\n",
    "3         Wii Sports Resort  Nintendo\n",
    "4  Pokemon Red/Pokemon Blue  Nintendo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora intenta usar query() para filtrar los datos. Guarda únicamente las filas en las que las columnas 'publisher' y 'developer' tengan los mismos valores. Tu objetivo es comprobar si las dos columnas son iguales. Para ello, selecciona el operador lógico que lo haga.\n",
    "\n",
    "La variable cols, que ya está presente en el precódigo, especifica las columnas que queremos seleccionar del resultado de la consulta. Para seleccionar solamente las columnas que nos interesan, utiliza la variable cols inmediatamente después del método query(). Esta es la sintaxis: df.query(...)[cols].\n",
    "\n",
    "Por último, asigna el resultado a una variable llamada df_filtered, luego imprime las primeras 5 filas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "cols = ['name', 'publisher', 'developer']\n",
    "\n",
    "df_filtered = df.query(\"publisher==developer\")[cols]\n",
    "print(df_filtered.head())\n",
    "\n",
    "#Resultado=============================\n",
    "                    name publisher developer\n",
    "0             Wii Sports  Nintendo  Nintendo\n",
    "2         Mario Kart Wii  Nintendo  Nintendo\n",
    "3      Wii Sports Resort  Nintendo  Nintendo\n",
    "6  New Super Mario Bros.  Nintendo  Nintendo\n",
    "7               Wii Play  Nintendo  Nintendo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado mediante el método isin()**\n",
    "\n",
    "El método que podemos utilizar para filtrar los datos se llama isin(). En lugar de utilizar los operadores lógicos conocidos, isin() comprueba si los valores de una columna coinciden con alguno de los valores de otra matriz, como una lista o un diccionario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "handhelds = ['3DS', 'DS', 'GB', 'GBA', 'PSP']\n",
    "print(df[df['platform'].isin(handhelds)][['name', 'platform']])\n",
    "\n",
    "#resultado ======================================\n",
    "\n",
    "                                                    name platform\n",
    "4                               Pokemon Red/Pokemon Blue       GB\n",
    "5                                                 Tetris       GB\n",
    "6                                  New Super Mario Bros.       DS\n",
    "10                                            Nintendogs       DS\n",
    "11                                         Mario Kart DS       DS\n",
    "...                                                  ...      ...\n",
    "16702                           Mezase!! Tsuri Master DS       DS\n",
    "16703  Eiyuu Densetsu: Sora no Kiseki Material Collec...      PSP\n",
    "16706                                           Plushees       DS\n",
    "16710                 Woody Woodpecker in Crazy Castle 5      GBA\n",
    "16715                                   Spirits & Spells      GBA\n",
    "\n",
    "[4801 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AHORA CON EL RESULTADO INVERTIDO POR EL SIMBOLO DE ~**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "handhelds = ['3DS', 'DS', 'GB', 'GBA', 'PSP']\n",
    "print(df[~df['platform'].isin(handhelds)][['name', 'platform']])\n",
    "\n",
    "#RESULTADO ==============================\n",
    "\n",
    "                                                                                                    name platform\n",
    "0                                            Wii Sports      Wii\n",
    "1                                     Super Mario Bros.      NES\n",
    "2                                        Mario Kart Wii      Wii\n",
    "3                                     Wii Sports Resort      Wii\n",
    "7                                              Wii Play      Wii\n",
    "...                                                 ...      ...\n",
    "16711  SCORE International Baja 1000: The Official Game      PS2\n",
    "16712                     Samurai Warriors: Sanada Maru      PS3\n",
    "16713                                  LMA Manager 2007     X360\n",
    "16714                           Haitaka no Psychedelica      PSV\n",
    "16716                               Winning Post 8 2016      PSV\n",
    "\n",
    "[11916 rows x 2 columns] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INCLUYENDO \"IN\" EN UN METODO QUERY**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "handhelds = ['3DS', 'DS', 'GB', 'GBA', 'PSP']\n",
    "print(df.query(\"platform in @handhelds\")[['name', 'platform']])\n",
    "\n",
    "#RESULTADO =================================\n",
    "\n",
    "                                                    name platform\n",
    "4                               Pokemon Red/Pokemon Blue       GB\n",
    "5                                                 Tetris       GB\n",
    "6                                  New Super Mario Bros.       DS\n",
    "10                                            Nintendogs       DS\n",
    "11                                         Mario Kart DS       DS\n",
    "...                                                  ...      ...\n",
    "16702                           Mezase!! Tsuri Master DS       DS\n",
    "16703  Eiyuu Densetsu: Sora no Kiseki Material Collec...      PSP\n",
    "16706                                           Plushees       DS\n",
    "16710                 Woody Woodpecker in Crazy Castle 5      GBA\n",
    "16715                                   Spirits & Spells      GBA\n",
    "\n",
    "[4801 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternativamente, puedes invertirlo con la palabra clave not in:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "handhelds = ['3DS', 'DS', 'GB', 'GBA', 'PSP']\n",
    "print(df.query(\"platform not in @handhelds\")[['name', 'platform']])\n",
    "\n",
    "#resultado =================================\n",
    "\n",
    "                                                                                                    name platform\n",
    "0                                            Wii Sports      Wii\n",
    "1                                     Super Mario Bros.      NES\n",
    "2                                        Mario Kart Wii      Wii\n",
    "3                                     Wii Sports Resort      Wii\n",
    "7                                              Wii Play      Wii\n",
    "...                                                 ...      ...\n",
    "16711  SCORE International Baja 1000: The Official Game      PS2\n",
    "16712                     Samurai Warriors: Sanada Maru      PS3\n",
    "16713                                  LMA Manager 2007     X360\n",
    "16714                           Haitaka no Psychedelica      PSV\n",
    "16716                               Winning Post 8 2016      PSV\n",
    "\n",
    "[11916 rows x 2 columns]\n",
    "\n",
    "\n",
    "#Como la variable handhelds es externa al DataFrame, tenemos que precederla con el símbolo @ en nuestra cadena de consulta, de lo contrario pandas intentará encontrar una columna llamada 'handhelds' y nos arrojará un error cuando no la encuentre.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**\n",
    "\n",
    "Imprime una lista de todos los géneros únicos en el conjunto de datos llamando al método unique() en la columna 'genre'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "df_mod = df[\"genre\"].unique()\n",
    "\n",
    "print(df_mod)\n",
    "\n",
    "#Resultado =========================================\n",
    "['Sports' 'Platform' 'Racing' 'Role-Playing' 'Puzzle' 'Misc' 'Shooter'\n",
    " 'Simulation' 'Action' 'Fighting' 'Adventure' 'Strategy']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Tenemos dos variables en el precódigo:\n",
    "\n",
    "- cols, que contiene las columnas de nuestro interés: 'name' y 'genre'\n",
    "- s_genres que es una lista de géneros que empiezan por la letra \"S\".\n",
    "\n",
    "Tu objetivo es utilizar el método isin() con la lista proporcionada s_genres para filtrar el DataFrame df de forma que solo se mantengan las filas en las que el género del juego no empiece por la letra \"S\".\n",
    "\n",
    "Cuando se filtran, utiliza la variable cols para seleccionar solo las columnas 'name' y 'genre' y asigna el resultado a una variable llamada df_filtered. Después muéstralo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "cols = ['name', 'genre']\n",
    "s_genres = ['Shooter', 'Simulation', 'Sports', 'Strategy']\n",
    "\n",
    "df_filtered = df[~df['genre'].isin(s_genres)][cols]\n",
    "print( df_filtered )\n",
    "\n",
    "#Resultado===============================================\n",
    "                                                   name         genre\n",
    "1                                     Super Mario Bros.      Platform\n",
    "2                                        Mario Kart Wii        Racing\n",
    "4                              Pokemon Red/Pokemon Blue  Role-Playing\n",
    "5                                                Tetris        Puzzle\n",
    "6                                 New Super Mario Bros.      Platform\n",
    "...                                                 ...           ...\n",
    "16710                Woody Woodpecker in Crazy Castle 5      Platform\n",
    "16711  SCORE International Baja 1000: The Official Game        Racing\n",
    "16712                     Samurai Warriors: Sanada Maru        Action\n",
    "16714                           Haitaka no Psychedelica     Adventure\n",
    "16715                                  Spirits & Spells      Platform\n",
    "\n",
    "[11489 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Vuelve a filtrar todos los géneros que no empiezan por \"S\", pero esta vez hazlo con el método query(). Para hacerlo, tendrás que utilizar la palabra clave not in en tu cadena de consulta. Utiliza cols para seleccionar solo las columnas 'name' y 'genre' y asigna el resultado a una variable llamada df_filtered. Después muéstralo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "\n",
    "cols = ['name', 'genre']\n",
    "s_genres = ['Shooter', 'Simulation', 'Sports', 'Strategy']\n",
    "\n",
    "df_filtered= df.query('genre not in @s_genres')[['name','genre']]\n",
    "\n",
    "print(df_filtered)\n",
    "\n",
    "#Resultado======================\n",
    "                                                   name         genre\n",
    "1                                     Super Mario Bros.      Platform\n",
    "2                                        Mario Kart Wii        Racing\n",
    "4                              Pokemon Red/Pokemon Blue  Role-Playing\n",
    "5                                                Tetris        Puzzle\n",
    "6                                 New Super Mario Bros.      Platform\n",
    "...                                                 ...           ...\n",
    "16710                Woody Woodpecker in Crazy Castle 5      Platform\n",
    "16711  SCORE International Baja 1000: The Official Game        Racing\n",
    "16712                     Samurai Warriors: Sanada Maru        Action\n",
    "16714                           Haitaka no Psychedelica     Adventure\n",
    "16715                                  Spirits & Spells      Platform\n",
    "\n",
    "[11489 rows x 2 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **=======================**\n",
    "\n",
    "## **Uso de estructuras de datos externas para filtrar DataFrames**\n",
    "\n",
    "filtrar utilizando diccionarios, Series e incluso otros DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n",
      "\n",
      "[2, 5, 10]\n",
      "\n",
      "    a  b  c\n",
      "0   2  5  X\n",
      "2  10  3  Y\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "our_list = [2, 5, 10]\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "print(df)\n",
    "print()\n",
    "print(our_list)\n",
    "print()\n",
    "print(df.query(\"a in @our_list\"))\n",
    "\n",
    "#Como podemos ver, query() devolvió todas las filas de df donde los valores de la columna 'a' están presentes en our_list. Esos valores son 2 y 10; la columna 'a' no contiene el valor 5.\n",
    "#Ten en cuenta que los valores del índice en el DataFrame filtrado no cambian respecto a sus valores originales, 0 y 2 en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado con un diccionario**\n",
    "\n",
    "Qué pasa si la variable almacena un diccionario en vez de una lista? Recuerda que los diccionarios se componen de pares clave-valor.\n",
    "\n",
    "Vamos a crear un diccionario y asignarlo a la variable our_dict. Para comprobar la presencia de valores de la columna 'a' entre los valores del diccionario, tenemos que utilizar el método values() del diccionario en nuestra consulta \"a in @our_dict.values()\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n",
      "\n",
      "{0: 10, 3: 11, 12: 12}\n",
      "\n",
      "    a  b  c\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "our_dict = {0: 10, 3: 11, 12: 12}\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "print(df)\n",
    "print()\n",
    "print(our_dict)\n",
    "print()\n",
    "print(df.query(\"a in @our_dict.values()\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los valores del diccionario (10, 11 y 12) aparece en la columna 'a' una vez, por lo que obtenemos tres filas de query(). Los valores del índice en el DataFrame filtrado no han cambiado. Filtrar con valores de diccionario es igual que filtrar con listas.\n",
    "\n",
    "Sin embargo, para comprobar la presencia de los valores de la columna 'a' entre las claves del diccionario (0, 3 y 12), necesitamos utilizar el query \"a in @our_dict.keys()\". La consulta más corta \"a in @our_dict\" también funcionará porque comprueba las claves por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n",
      "\n",
      "{0: 10, 3: 11, 12: 12}\n",
      "\n",
      "    a  b  c\n",
      "1   3  4  Y\n",
      "4  12  1  Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "our_dict = {0: 10, 3: 11, 12: 12}\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "print(df)\n",
    "print()\n",
    "print(our_dict)\n",
    "print()\n",
    "print(df.query(\"a in @our_dict\")) #por defecto, pero tambien puedes usar \"a in @our_dict.keys()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado con un Series**\n",
    "\n",
    "Ahora veamos un ejemplo en el que la estructura de datos externa es un objeto Series. Tal y como los diccionarios almacenan pares clave-valor, los objetos Series almacenan pares índice-valor. Sin embargo, en el caso de los objetos Series, los valores se comprueban por defecto.\n",
    "\n",
    "La consulta \"a in @our_series\" comprobará la presencia de valores en la columna 'a' entre los valores de our_series en lugar de su índice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n",
      "\n",
      "0    10\n",
      "1    11\n",
      "2    12\n",
      "dtype: int64\n",
      "\n",
      "    a  b  c\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "our_series = pd.Series([10, 11, 12])\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "print(df)\n",
    "print()\n",
    "print(our_series)\n",
    "print()\n",
    "print(df.query(\"a in @our_series\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza el atributo index de our_series de abajo para escribir una consulta que filtre a df para mantener solo las filas cuyos valores de la columna 'c' están también presentes en el índice de our_series. Imprime el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "our_series = pd.Series([10, 11, 12], index=[\"X\", \"Y\", \"T\"])\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df.query(\"c in @our_series.index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado con un DataFrame**\n",
    "\n",
    "También podemos utilizar un DataFrame externo para filtrar nuestros datos de dos maneras:\n",
    "\n",
    "- Filtrar utilizando sus valores de índice.\n",
    "- Filtrar utilizando valores de columnas específicas.\n",
    "\n",
    "Para filtrar basándonos en la inclusión entre los valores del índice de un DataFrame externo, simplemente lo tenemos que comprobar de la misma manera que lo hicimos para un índice de Series: accedemos al atributo index en nuestra consulta.\n",
    "\n",
    "Vamos a crear un DataFrame externo llamado our_df con valores de índice establecidos por la lista ['Z', 'X', 'P']. A continuación, podemos comprobar los valores de la columna 'c' para incluirlos en el índice de our_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a  b  c\n",
      "0   2  5  X\n",
      "1   3  4  Y\n",
      "2  10  3  Y\n",
      "3  11  2  Y\n",
      "4  12  1  Z\n",
      "\n",
      "   a1  b1 c1\n",
      "Z   2   3  A\n",
      "X   4   2  B\n",
      "P   6   2  C\n",
      "\n",
      "    a  b  c\n",
      "0   2  5  X\n",
      "4  12  1  Z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "our_df = pd.DataFrame(\n",
    "    {\n",
    "        \"a1\": [2, 4, 6],\n",
    "        \"b1\": [3, 2, 2],\n",
    "        \"c1\": [\"A\", \"B\", \"C\"],\n",
    "    },\n",
    "    index=[\"Z\", \"X\", \"P\"],\n",
    ")\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(our_df)\n",
    "print()\n",
    "print(df.query(\"c in @our_df.index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar si los valores de la columna del DataFrame que queremos filtrar (df en este caso) también están presentes en la columna de un DataFrame externo (our_df), tenemos que especificar la columna externa en nuestra consulta utilizando la notación de puntos.\n",
    "\n",
    "La consulta \"a in @our_df.a1\" comprueba si algunos valores de la columna 'a' de df están presentes en la columna 'a1' de our_df.\n",
    "\n",
    "Podemos utilizar como atributos la notación de puntos para acceder a las columnas de un DataFrame en lugar de la notación de corchetes, por lo que our_df['a1'] es equivalente a our_df.a1. Pero en las cadenas de consulta, solo funcionará la notación de puntos.\n",
    "\n",
    "Utiliza lo que acabas de aprender para filtrar df de forma que solo mantengas las filas en las que los valores de la columna 'a' estén también presentes en la columna 'b1' del DataFrame externo our_df. Imprime el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  2  5  X\n",
      "1  3  4  Y\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": [2, 3, 10, 11, 12],\n",
    "        \"b\": [5, 4, 3, 2, 1],\n",
    "        \"c\": [\"X\", \"Y\", \"Y\", \"Y\", \"Z\"],\n",
    "    }\n",
    ")\n",
    "our_df = pd.DataFrame(\n",
    "    {\n",
    "        \"a1\": [2, 4, 6],\n",
    "        \"b1\": [3, 2, 2],\n",
    "        \"c1\": [\"A\", \"B\", \"C\"],\n",
    "    },\n",
    "    index=[\"Z\", \"X\", \"P\"],\n",
    ")\n",
    "\n",
    "print(df.query(\"a in @our_df.b1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **=====================**\n",
    "## **Filtrado por condiciones múltiples**\n",
    "\n",
    "Filtraremos de manera mas compleja basado en más de una condicion lógica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce')\n",
    "\n",
    "print(df[(df['platform'] == 'Wii') & ~(df['genre'] == 'Sports')].head())\n",
    "\n",
    "#Resultado =================================\n",
    "\n",
    "                         name platform  year_of_release     genre publisher  \\\n",
    "2              Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
    "7                    Wii Play      Wii           2006.0      Misc  Nintendo   \n",
    "8   New Super Mario Bros. Wii      Wii           2009.0  Platform  Nintendo   \n",
    "39    Super Smash Bros. Brawl      Wii           2008.0  Fighting  Nintendo   \n",
    "49         Super Mario Galaxy      Wii           2007.0  Platform  Nintendo   \n",
    "\n",
    "    developer  na_sales  eu_sales  jp_sales  critic_score  user_score  \n",
    "2    Nintendo     15.68     12.76      3.79          82.0         8.3  \n",
    "7    Nintendo     13.96      9.18      2.93          58.0         6.6  \n",
    "8    Nintendo     14.44      6.94      4.70          87.0         8.4  \n",
    "39  Game Arts      6.62      2.55      2.66          93.0         8.9  \n",
    "49   Nintendo      6.06      3.35      1.20          97.0         8.9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Ahora exploremos una condición “or” obteniendo todos los juegos que superaron el millón de dólares en ventas en al menos una de las tres regiones:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce')\n",
    "\n",
    "print(df[(df['na_sales'] >= 1) | (df['eu_sales'] >= 1) | (df['jp_sales'] >= 1)].head())\n",
    "\n",
    "#resultado =======================\n",
    "\n",
    "                       name platform  year_of_release         genre publisher  \\\n",
    "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
    "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
    "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
    "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
    "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
    "\n",
    "  developer  na_sales  eu_sales  jp_sales  critic_score  user_score  \n",
    "0  Nintendo     41.36     28.96      3.77          76.0         8.0  \n",
    "1       NaN     29.08      3.58      6.81           NaN         NaN  \n",
    "2  Nintendo     15.68     12.76      3.79          82.0         8.3  \n",
    "3  Nintendo     15.61     10.93      3.28          80.0         8.0  \n",
    "4       NaN     11.27      8.89     10.22           NaN         NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtra el df para que solo salgan los juegos que salieron en la década de los 80. Asigna el resultado a una variable llamada df_filtered y luego imprime las primeras 5 filas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce')\n",
    "\n",
    "df_filtered = df[(df['year_of_release']>=1980) & (df['year_of_release']<1990)]\n",
    "print(df_filtered.head(5) )\n",
    "\n",
    "#resultado =======================\n",
    "\n",
    "                   name platform  ...  critic_score user_score\n",
    "1     Super Mario Bros.      NES  ...           NaN        NaN\n",
    "5                Tetris       GB  ...           NaN        NaN\n",
    "9             Duck Hunt      NES  ...           NaN        NaN\n",
    "21     Super Mario Land       GB  ...           NaN        NaN\n",
    "22  Super Mario Bros. 3      NES  ...           NaN        NaN\n",
    "\n",
    "[5 rows x 11 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CONDICIONES MÚLTIPLES CON query()**\n",
    "\n",
    "También podemos filtrar por múltiples condiciones escribiendo cadenas de consulta para el método query(). Vamos a filtrar para obtener solo los juegos de Wii que no sean deportivos, pero esta vez con una cadena de consulta:\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce')\n",
    "\n",
    "print(df.query(\"platform == 'Wii' and genre != 'Sports'\").head())\n",
    "\n",
    "#Resultado ============================================\n",
    "\n",
    "                         name platform  year_of_release     genre publisher  \\\n",
    "2              Mario Kart Wii      Wii           2008.0    Racing  Nintendo   \n",
    "7                    Wii Play      Wii           2006.0      Misc  Nintendo   \n",
    "8   New Super Mario Bros. Wii      Wii           2009.0  Platform  Nintendo   \n",
    "39    Super Smash Bros. Brawl      Wii           2008.0  Fighting  Nintendo   \n",
    "49         Super Mario Galaxy      Wii           2007.0  Platform  Nintendo   \n",
    "\n",
    "    developer  na_sales  eu_sales  jp_sales  critic_score  user_score  \n",
    "2    Nintendo     15.68     12.76      3.79          82.0         8.3  \n",
    "7    Nintendo     13.96      9.18      2.93          58.0         6.6  \n",
    "8    Nintendo     14.44      6.94      4.70          87.0         8.4  \n",
    "39  Game Arts      6.62      2.55      2.66          93.0         8.9  \n",
    "49   Nintendo      6.06      3.35      1.20          97.0         8.9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo tomamos las filas que superaban el millón de dólares en ventas en al menos una de las tres regiones. Realiza el mismo filtrado abajo, pero esta vez utilizando query(). \n",
    "\n",
    "Asigna tu cadena de consulta a una variable llamada q_string, luego imprime las primeras 5 filas del resultado de llamar a query() en df con q_string como entrada.\n",
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/vg_sales.csv')\n",
    "df['user_score'] = pd.to_numeric(df['user_score'], errors='coerce')\n",
    "\n",
    "q_string = \"na_sales >= 1 or eu_sales >= 1 or jp_sales >= 1\"\n",
    "df.query(q_string) #atencion a esta parte\n",
    "print(df.query(q_string).head(5)) \n",
    "\n",
    "#Resultado================\n",
    "                       name platform  ...  critic_score user_score\n",
    "0                Wii Sports      Wii  ...          76.0        8.0\n",
    "1         Super Mario Bros.      NES  ...           NaN        NaN\n",
    "2            Mario Kart Wii      Wii  ...          82.0        8.3\n",
    "3         Wii Sports Resort      Wii  ...          80.0        8.0\n",
    "4  Pokemon Red/Pokemon Blue       GB  ...           NaN        NaN\n",
    "\n",
    "[5 rows x 11 columns]\n",
    "\n",
    "#recordar y revisar la parte en la que tienes string y la pasas a query\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
